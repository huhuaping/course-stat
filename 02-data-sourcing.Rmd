---
output:
  xaringan::moon_reader:
    seal: false
    lib_dir: libs
    css: 
      - default
      - default-fonts
      - duke-blue
      - hygge-duke
      - libs/cc-fonts.css
      - libs/figure-captions.css
      - libs/mycss/my-custom.css
    nature:
      highlightStyle: github
      highlightLines: true
      countIncrementalSlides: false
      ratio: "16:9"

---
background-image: url("pic/slide-front-page.jpg")
class: center,middle

# 统计学原理(Statistic)

<!---    chakra: libs/remark-latest.min.js --->

### 胡华平

### 西北农林科技大学

### 经济管理学院数量经济教研室

### huhuaping01@hotmail.com

### `r Sys.Date()`

```{r global_options, echo=F,message=FALSE,warning=F}
source("R/set-global.R")

```


```{r ex-math-eq}
source("R/external-math-equation.R")
```

<style type="text/css">
.remark-slide-content {
    font-size: 24px;
    padding: 1em 4em 1em 4em;
}
</style>

---
class: inverse, center, middle
# 第二章

## 数据收集、整理和清洗

---
layout: false
class: inverse, center, middle, duke-softblue

# 2.1 数据来源与形式

---
layout: true
  
<div class="my-header"></div>

<div class="my-footer"><span>huhuaping@   第02章 数据收集、整理和清洗   
&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;
&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;
2.1 数据来源与形式</span></div> 

---

## 数据来源

不同研究方法会产生不同类型数据：

- 观察数据

- 调查数据

- 实验数据


---

## 数据来源

从产生数据的方式方法上又可以有：

- 问卷数据

- 访谈数据

- 文献数据

- 痕迹数据：大数据。（注意不是**痕迹证据**！）

在获得数据的同时，  应该还有一份数据，是记录数据获得过程的，通常称之为日志，  它要记录数据是从哪里来的、什么情况下得到的、数据的基本特征又是什么，  比如文字数据有多少页、图片数据有多少张，这就是日志数据


---

## 数据载体和形态


从是否数字化来看：

- 数字化的数据

- 非数字化的数据


从是否数值化来看：

- 数值数据

- 非数值数据

---

## 数据载体和形态

从具体形态来看：

- 文本数据：
    
    - 访问、观察中的文字记录
    - 数字化的字符形态的数据
    - 任何文字加载体的数据，比如文字加载于纸张、羊皮卷等

- 图片数据：

    - 访谈时拍的照片、搜集到的图片、照片的底片等等
    - 数字化为像素点形态的图片数据
    - 任何图形加载体的数据，比如图形加载于纸张、胶片、计算机存储等

---

## 数据载体和形态

- 音频数据：
    - 访问录音、观察中的语音日志、搜集到的音频记录等。 
    - 数字化为波形形态的音频数据。
    - 任何音频加上载体，比如音频加载于钢丝、胶片、磁带、光碟、磁碟、闪存盘、硬盘等

- 视频数据：
    - 访谈时的全程录像、搜集到的各种各样视频。
    - 数字化为像素点加上波形形态的视频数据
    - 视频加上载体，比如比如视频加载于胶片、光碟、闪存盘、硬盘等
    
- 实物数据

    - 任何有实物才可以完整保存信息的实物载体数据
    - 访谈中搜集到的实物、观察中观察到的实物，比如出土文物、建筑等

???

数据的类型主要依据来源和载体形态有不同的划。

对数据整理而言，载体形态是最基本的分类，不同载体形态的整理方式会有不同。 

---

### 课堂思考


以上关于数据来源与形式的分类是完全是互斥的吗？

以调查问卷为例：

- 传统纸版问卷，主要是文字、图片形态的数据。

- 新媒体电子问卷，不管是哪一个类型的电子问卷，主要是数据形态的数据，当然也会有图片的、音频的、视频的数据。 


以上的分类并不完全是互斥的，只是根据显性的特征来做一些划分，其实我们很难找到一个标准把数据的形态类型区分得非常清楚。 

???

有同学可能会说：“老师，问卷上不是有数吗？”数在数字化里有两个定义的，一个是字符型的，一个是数值型的，有不同的含义；在纸版上不管是数还是字，都是文字形，在纸版问卷中，除了数还有图片，或者是图画，只有这两个形态的数据。  


---

### 课堂思考

数字与数值是一个意思吗？

图片、音频、视频看起来的确是数字的，但数字不等于数值！

- 传统照片不是数字的。

- 数码照片的数字指的是像素点的数字

- 音频、视频是同样的道理。


---

### 课堂思考

>“老师，不管什么时候我都要用计算机做笔记的。” 

信息化时代，传统手写记录的文本数据是不是越来越没有价值？

- 用计算机或各类终端设备来做电子化记录。

- 用笔和本子做传统记录。 

---
layout: false
class: inverse, center, middle, duke-softblue

# 2.2 数据收集

---
layout: true
  
<div class="my-header"></div>

<div class="my-footer"><span>huhuaping@   第02章 数据收集、整理和清洗   
&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;
&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;
2.2 数据收集</span></div> 

---

知道了研究数据与数据的区别 知道了数据的各种形态，那么数据从哪里来呢？实证研究要用数据
都需要自己去采集吗？ 为了理解数据的来源，我需要再次强调没有数据就没有研究。
不过这并不意味着，研究需要的数据都需要研究者自己去采集
即使需要搜集数据，也不一定需要研究者到现场去采集。
认为实证研究的数据都是研究者自己采集的 那是一个很大的误区，尽管只要有实证研究，就一定要有数据。
正因为如此，实证研究其实已经积累了 很多的数据。经常有同学跟我说：“老师，我要做一个研究”
我可能反馈他的第一句话就是：“你的数据从哪里来?” 而不会问他怎么调查数据。
数据从哪里来和怎么调查数据是两回事，希望大家能够明白。
那么，用于研究的数据到底从哪里来呢？还记得北京大学本科生
入学机会的地区不平等的例子？其中涉及地区划分的数据从哪里来？
从政府部分来，对不？Morphy等人的研究数据从哪里来？
从新西兰和英国的调查数据中来，也不是他们自己搜集的。
这就是研究数据的第一类来源：已经存在的数据。
研究数据的第二类来源，是将要产生的数据。
不管采用什么方式产生，调查也好，自动 积累也好，现在没有，但是不久的将来会有的数据。
先来看看已有的数据，注意，已有并不意味着
所有已经存在的数据都可以拿来做研究，理论上是可以，但实践中
还有诸多的影响因素。已有的数据，指的是已经公开的，且可以直接使用的数据。
一般来讲，凡是公开的数据正是出版的数据、发布的数据，都是可以 直接使用的数据，譬如
政府的各类统计数据，包括经济、就业、人口、健康、教育、产业
等等的统计数据，不仅仅中国政府，任何一个运作正常的政府 都有这样的数据；再比如，上市公司的公开数据
根据上市相关的法律，公司的财务数据、生产数据 应该都是公开的；还有呢，研究机构或者研究者个人公开的数据
这一类数据有很多都可以直接拿来用；在所有这些已经存在的数据中
有相当的部分是无需授权就可以使用的数据，比如，正式出版物提供的数据
只需要在使用说明中正式说明出处，就不需要授权。
除了无须授权的公开数据，也有一部分数据是需要授权的。
其中既包括了公开的数据，也包括未公开的数据。
有些已经公开的数据，尤其是学术性的调查数据
按照学术规范呢，虽然已经公开了，不过，如果你要使用，还是需要申请并且被授权。
大多数的学术研究数据，无论是机构性的还是个人性的数据 都采用了这样的规则。
一些没有公开的数据呢，通过授权形式，也是可以使用的，比如说，行为痕迹管理机构的数据- ，包括政府数据
赢利和非赢利服务机构的数据；什么叫政府数据？ 大家每年的收入，政府是了解的。
按照世界上主要国家的法律，公民是有义务向国家申报每年收入状况的
国际要根据这些数据来收取个人所得税；在中国
几乎任何一笔收入，只要不是灰色收入，都是经过机构的，都有管理
只要有管理的，都有痕迹数据；再比如说，银行数据，每个人
都有银行账号，各位都有，每年的收入支出，只要是经过银行卡的，都有数据。
这些都叫行为管理机构的数据。还有电性数据，包括电脑呀、电话呀
只要是通过网络通信的数据，都有人帮你记着。
有的同学可能会担心了：“老师，他们保存多长呀？”，很难说啊。
北京大学的李晓宁教授，专门搜集网页数据 中国自互联网诞生以来所有中文网页的数据，他都收着。
说到网上行为，建议大家看一本书，讲的就是行为痕迹数据，叫《删除》，Schonber- ger写的。
这一类的数据，对于社会科学研究而言
是一座金矿，老一代的学者已经没有技术能力来运用这些数据了 但是对青年学者，对你们，是一座金矿。
除此以外呢，一些主要的数据管理机构做了一些数据集成的工作。
对学术研究而言，比如说，ICPSR，是大家不应该忽视的
一个数据源，目前看来，似乎是世界上最大的学术数据源。
在中国国内也有，比如北京大学呀，中国人民大学、清华大学、中国疾病控制中心 都有类似的数据。接下来我要给大家介绍几个主要的数据来源
ICPSR，美国大学联盟的数据集成中心，机构呢是在密歇根。
ISSS，北京大学中国社会科学调查中心，我创办的
主要的数据源为CLPS；“中国家庭跟踪调查”也是北京大学委托我创立的
NSRC，中国人民大学中国调查与数据中心，主要的数据源是CGSS，中国综合社会调查
CDC，中国疾病控制中心，主要的数据源包括了慢病、流行病、艾滋病等多种 涉及健康与疾病的调查。
每一个机构的网页，大家通过搜索引擎就可以找到，这里呢，我就不花时间了。
如果大家有需要，请在讨论版上提出来，我们可以专门录一段视频 供大家参考。如果依据数据使用的时序
对大多数研究者来说，已有的数据就是二手数据。
二手数据指什么？指已经被使用过的，我们拿来再做分析
同样的数据集，使用不同的方法，甚至不同的研究主题和研究目的。
当然对于二手数据的再分析，可以使用不同的数据集，也可以采用相同的方法，相同的主题
或者不同的主题。前者呢，是为了检验或者商榷；后者，则可以用于不同的研究目的。还有
也可以用不同的数据集，不同的方法以达成特定的研究目的。
问题是二手数据从哪里来呢？可以从研究主持者那里来
也有研究主持者，在自己的研究完成之后，就把数据交给了数据管理机构
数据管理机构呢，是最大的二手数据来源，我提醒一下，按照学术规范
研究者发表研究成果需要说明数据来源，千万别忘记了。
要使用二手数据，就免不了产生技术性的问题 比如数据格式的转换呀，从编码呀，数据的加工呀等等
技术性的问题，可以参考哈佛大学和MIT联合建立的IQSS
他们一直在探讨非常前沿的数据加工方法。
基本的技术，我们在数据整理的部分再详细讲。
除了已经存在的数据，第二大类来源就是将要产生的数据。
没有人会无缘无故地搜集数据，只要是搜集数据，总是有目的的。
那么，将要产生的第一类数据，就是系统采集的数据，比如说
政府统计数据呀，公司统计数据呀，各类来源的大数据呀 再比如学术机构，作为基础设施建设的系统调查数据
这里，像美国的GSS，由芝加哥大学调查的数据 PSID，密歇根大学调查的数据；HRS，密歇根大学调查的
数据；Understanding Society，艾塞克斯大学调查的数据等等。
几乎主要的国家都有大型的以学术研究为目的的综合性数据。
中国也有，大家已经知道一些了
比如，CFPS，CGSS，GSS(c)，CHIPS，CHNS，CHFS等等
这一些数据，大家运用搜索引擎一搜，就能搜到，因为它们太有名了。
除了综合性的数据，还有专题性的数据，比如，北京大学曾毅 教授主持的中国老人健康长寿影响因素研究
清华大学李强教授主持的中国城镇化与劳动移民 类似的数据非常地多，大家可以根据自己的兴趣
用相关的数据来试一试。
对初学者而言呢，大家在试的时候，千万要注意数据的优势与不足
任何一个数据集，只要不是专门为某个研究目的设计的，都会希望
尽量照顾到更多的需求。这就构成了一个难题 到底是用综合数据，还是用专题数据？
如果着眼于综合数据，就不一定能够满足专业兴趣的要求和需求。
还是我们的例子：入学机会不平等研究， 做这项研究需要用到地区性的当年高中毕业生人数
地区性的当年的经济收入数据、地区性的当年城乡户籍人口数据。
如果用综合数据，这些专题数据显然就找不着。
在政府数据中，倒是可以找到一些，但是，你需要根据专题去清理、去加工。
除此以外，考入北京大学的学生人数和iii 北京大学的招办就有，其实这种困难是比较好克服的，怕就怕
你非常有兴趣地研究问题，去哪儿却也找不到数据。
如果没有办法从既有的综合性数据中获取必须的数据
那就得自己加工数据了，我举一个例子：“个性化”研究的数据。
阎云翔教授使用了人类学的数据 我自己呢，则从CFPS和CJSS两个数据集中
加工了一些数据，尽管如此，还是不能完全满足我的研究要求 这个时候就得自己开始采集数据了。
将要采集的数据包括你自己采集的数据，其中的一类
就是社会调查数据；注意，社会调查数据在这里是一个比较狭窄的说辞
社会调查数据，理论上，我们找到的数据都是调查数据，虽然调查方式不一样，那也是调- 查数据呀
比如说，你请计算机系的同学帮你使用网络爬虫爬下来的数据，那也是调查数据 但是在这里，特指专题性的
通过自己设计、调查执行获得的研究数据
包括刚才讲的大数据。所以需要特别提醒大家的是：自己调查数据是一个
不得已的选择，对任何研究者而言，都应该是第二选择
而不是第一选择，如果你的研究能够使用已经存在的数据，尤其是很多人用过的数据
最好用这样的数据；为什么呢？第一，数据的可靠性已经被检验过了；第二呢，研究的成果具- 有可比性
有同样的数据做不同的研究，具有很好的可比性。
如果依据研究设计
需要通过调查来获取数据，这需要一项专门的能力，包括组织能力 也是这我们这门课希望培养的能力，它包括了，比如说
获取数据的能力呀、评估数据质量的能力呀、有效运用 数据的能力呀，更重要的是，如果需要通过调查获取数据
还一定要有资源；如果说没有数据，就无法做实证研究，那么没有资源就无法通过调查获- 取数据。
无论是运用已经存在的数据，还是自己通过调查采集的数据
为了有效地运用数据，我们还需要知道数据的时间维度特征。
从数据之间在时间维度上的关联性来看，我们可以把数据分为 截面数据和跟踪数据。截面数据，cross
section data 就是一个始点上的数据；我们知道事物的发展总是在时间维度上展开的。
大多数的专题研究 只要没有声明跟踪研究，那都是截面数据。在综合性的调查中，比如说：GSS,
CGSS 都是截面数据。如果每一个始点的调查 调查内容具有可比性，例如，用于计算CPA的调查
在这类调查中获得的数据就是缺失数据，最典型的缺失数据还有人口普查数据。
跟踪数据，经济学中又叫“面板数据”，是pannel data的直译
非常糟糕的翻译，让人无法理解 我们还是叫跟踪数据比较好。这是一类锁定调查对象以后，不更换调查对象
在时间维度上不断进行调查的数据，经过多长时间调查一次，需要根据变量属性的特征来确定。
在学术界，最悠久的一个数据集就是PSID
从1968年到现在，还在跟踪调查；我创立的CFPS也是这一类
两种数据各有优缺点，运用方法呢，也有不同的要求。
这些已经属于研究生课程的内容，在这里就不讲了 知道有这些不同的数据就好。下边对这一节的内容做一个小结。
十年前在中国做研究也许找不到数据 十年以后的今天，情况就不一样了，数据不那么短缺了。
研究数据有多种、多重的来源 好好运用既有的数据是研究者的第一选择；第二
获取已经存在的数据有很多个方法，也有多种途径 第三，万一没有办法获取需要的研究数据，那就只好自己动手。
有同学说：“既然有这么多的数据，这门课是不是可以不学了？” 我的回答是：“这门课你不仅要学，而且要认认真真地学”
因为，如果你不了解数据是怎么获得的，你就没有能力甄别 已有的数据到底可不可靠、可不可用，你甚至都不知道上哪儿去找数据。
无论是运用已有的数据，还是自己调查数据，都需要知道 截面数据、跟踪数据的特征、优势、劣势。
这一部分的内容就到这里。这一周的内容跨度比较大
从研究问题到研究数据，内容也比较多，从知识到技能。
这里呢，做一个简要的归纳。
在实证研究中，研究问题是社会情境下 事物之间关系模式的概念化或者变量化表述。
这一些问题主要来自于理论与现实之间的张力，既可以从理论演绎中来 也可以从生活实践的归纳中来。
对研究者而言呢，选择研究问题，需要满足可行、妥当、重要三原则。
可行，自己要有能力做，才是最重要的。
研究问题的操作化，就是把研究问题转化为具体的研究题目。
研究题目，表述的是两个概念或者变量之间的关联。
研究数据，指的是结构化的、反应事物属性的、满足研究目的的数据集。
在不同的情境下，数据具有不同的形态 原始数据一般不能直接用于研究。
研究数据有多种多样的形态，对研究而言，重要的是 结构化的、有变量、数值、变量、属性标签的数据。
研究数据的来源多样，自己调查数据是研究者不得已的选择。
即使如此，掌握数据采集的知识与能力，是用好数据的基础。
这一周的内容就到这里，谢谢大家。


---

## 收集二手数据


---

## 收集调查数据




---

## 收集实验数据


---
layout: false
class: inverse, center, middle, duke-softblue

# 2.2 抽样设计

---
layout: true
  
<div class="my-header"></div>

<div class="my-footer"><span>huhuaping@   第02章 数据收集、整理和清洗   
&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;
&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;
2.2 抽样设计</span></div> 

---

## 什么是抽样

这几周来，通过慢慢的积累，我们已经有了理论，
有了题目，假设我们希望通过自己调查来获得数据，为此呢，已经做了一切的前期准备工作，
比如已经把概念操作化为变量了， 也知道怎么样去运用测量工具，那么在进度调查之前，我们还需要知道
调查谁。这一周，我们将讨论获得调查对象时，最重要的一种方法—抽样方法。
这一周的课程有两个目的，第一个目的， 了解抽样的逻辑，包括概率抽样的逻辑和非概率抽样的逻辑；
第二个目的，是要同学们掌握抽样设计与抽样方法，知道怎么样设计，怎么样抽样。
鉴于既涉及原理，又涉及技术， 这一周的内容会多一些，希望大家有一些耐心。
基本的内容包括，第一，对抽样的基本原理要做一个介绍；
第二，对抽样的要素，要让大家理解一个抽样哪些要素是必须的；
第三，有了要素，抽样活动又遵循怎样的逻辑；
第四，技术上，什么条件该要采用概率抽样方法，怎么样做概率抽样设计；
第五，什么条件下要采用非概率抽样方法，又如何做非概率抽样；
第六，一个抽样方案应该包括哪些内容；
第七，拿到了一个抽样方法、抽样方案，又怎么样去实施抽样。
我们从抽样的基本原理入手， 理解抽样的原理，对理解抽样的方法及其适用的情境，非常重要。
讲枯燥的原理是同学们反对的，我也觉得很无聊，我们还是用例子吧。
还记得我们的课题吗？北京大学本科生入学机会的地区不平等研究。
这个题我们已经做到哪一步啦？我们已经把研究问题操作化了，记得不？
地区经济发展水平与进入北京大学的机会。
相关的概念我们也操作化了，对吗？ 地区，我们可以根据经济发展水平，把省级单位作为地区区分的基本单位，
依据经济发展水平，区分为高、中、低三个类型。
有同学可能会问：“老师，怎么划分高、中、低呢？"。
在方法上可能比较简单，如果有数据，有31个省、市、自治区的数据，
我们就可以看各省级单位的人均GDP，
人均GDP，是可以比较的参数，对吧？我们就用这个参数， 用各省级单位人均GDP进行排序，
由高到低，由低到高都行，但要有相同的规则。
根据变量值分布的相对集中程度吧，我们可以把 31个省级单位分为人均GDP的
高、中、低三个组。
当然还有比较复杂的方法，比如说用多个经济指标进行聚类，
根据多个经济指标对教育的影响计算权重，再分类等等。
这里呢，我们采用最简单的方法，也可能是最有效的，同学们能够做的方法。
再看城乡的区分。
城乡的区分比较简单，我们已经讨论过了，由于学生的 受教育机会主要是受户籍特征的影响，
所以，按照农业户籍和非农业户籍进行划分就好了。
这里我提醒同学们，如果想了解中国的户籍制度，以及户籍制度对人们社会经济生活所带来- 的影响，
建议大家找一些文献进行阅读，做社会研究， 不了解中国社会，是很难做研究的。接着看入学机会，
用某地区当年被北京大学录取的学生数， 除以该地区当年高中毕业生的总数，再乘以100%。
大家还记得这里采用的是能力不平等，对吗？ 是否平等，是我们的因变量，
我们要比较的正是6类地区的入学机会，据此判断入学机会 是否与经济发展水平有关。
从这儿的操作化来看，我们并没有用到超出我们知识水平和能力范围的内容，对吧？
为下一步操作的方便，有一些问题，还需要
进一步地推敲，比如经济发展水平，虽然采用了人均DGP， 虽然已经做了很强的假设，大家还记得我们假设
不同地区的经济发展水平是同质的， 可我们还是不放心，我们知道一个省内不同地区的经济发展水平是有差异的，
因此会犹豫，是只考虑省级之间的差异呢？ 还是降低层级，比如说，也考虑地市级之间的差异呢？
如果考虑地市级之间的差异，那么在一个省级单位内，
是把所有的地市级都纳入呢，还是在抽取了省级单位以后， 再把抽到的省级单位的所有地区纳入？
还是说在抽取省级单位之前，就考虑地市级之间的差距，用地市级单位
进行排队，直接抽取地市级单位呢？ 不管是采用省级单位，还是采用地市级单位，
另一个需要考虑的问题就是，在划分时，要不要把毕业生数量作为一个影响因素？
再看毕业生，要把31个省级单位的全部高中毕业生都纳入搜集数据的范围吗？ 还是只搜集其中的一部分就够了？
如果只搜集其中的一部分，我们怎么选高中呢？这一些 都是在调查实施之前要推敲的问题，
之所以要推敲，是因为关系到研究的误差。
在进一步推敲之前，我们先看一些事实，北京大学的本科生， 不是以县级单位为基本单位录取的，
也不是以地市级为基本单位录取的，而是以省级为基本单位录取的，不仅如此，
初等教育的资源配置也是以省级为基本单位的，因此呢，第一个问题似乎就解决了。
那么是否调查全部的高中毕业生呢？还记得我们曾经假设地区内部
具有高度的同质性？事实上同质性是人类社会普遍存在的现象，
对我们的调查而言，同质性意味着变量属性的相似 或者相等，意味着我们无需调查全部的高中毕业生。
我们举一个例子，比如说我们买了100支同样的铅笔， 结账的时候，到底是用乘法，还是用加法？
可能同学们马上会说：“老师，这个问题是不是有点2啊？” 不，对抽样而言，这的确是一个问题，
看起来是生活中一个不需要想的问题，在这儿，却真的要想清楚， 到底是使用乘法，还是使用加法？
大家都会说：“当然使用乘法了！” 的确，如果使用加法，就意味着要对全部的毕业生进行调查；
使用乘法呢，就意味着可以对同类学生中的一位进行调查，
再乘以同类学生的数量。可是为什么要使用乘法？ 是因为尽管两者的结果是一样的，
使用乘法要快得多。快， 在调查上就意味着节省，省时间、省金钱、
省人力、省物力。这是人类社会行为的动力， 某个变量属性在人群中的分布，有异质性，也有同质性，
前面我们假设同质性，在实践中是很冒险的做法，我们知道有些地区的中学
考上北京大学的人每年都有，另一些地区的中学呢？ 多少年都没有一位，也就是说，在一个省级单位内部，
地区之间就考上北京大学的毕业生而言，是 异质性的，如此，就不能用一位来代表全部的学生，而
需要用不同数量的毕业生来代表不同类型的毕业生，抽样问题也就出现了。
在群体中，抽选代表性群体的做法，
在调查中，就是“抽样”。我们知道在一个群体中，既有同质性的，也有异质性的，
抽取一个代表不了，那么就地区经济发展水平而言，虽然已经区分了高、中、低三类，
每一类中，其实也存在着很大的异质性。
接下来的问题就是在每一类中抽选多少，才可以代表这一类内部的异质性呢？
这就是抽样、抽样设计、抽样方法要探讨的问题了。
有同学可能会说：“既然存在异质性，干脆把全部高中毕业生都纳入不就得了？”
问题是任何一项研究都会面对资源的约束，
假设这是博士研究生自己的项目，不是教育部委托的，你们认为他有资源调查全部的毕业生吗？
一方面，资源有限，迫使研究者采用抽样的方法，而不是普查的方法，
从研究对象那里去获得数据；另一方面呢，
在研究对象中，事实上存在着同质性，也迫使普查不仅浪费资源，
也毫无必要。还有，即使你有资源，甚至愿意做普查，也不是想普查就能普查的，
有时候一些研究对象也不可及呀，你不忙人家还忙着呢！
在这种情况下，采用同质性代表的方法甚至比普查还要靠谱。
当然抽样也有局限性，如果研究对象的分布非常广泛，对调查而言，
就是很麻烦的事，比如CFPS， 在抽样设计中就受到了研究对象分布太广的影响，
理论上，CFPS要代表的是中国大陆的所有家庭，
可是在新疆西藏的牧区，调查对象的分布实在太广了，在那儿调查一户人家所花费的资源
可能是在城镇地区的多少倍，我实在没有这些资源，就只好放弃。还有，
如果研究对象的数量非常稀少，比如说铊中毒， 大家可能比较熟悉，假设我们希望研究铊中毒人群的分布，
由于对象的数量实在太少，采用抽样的方法几乎就不可能
获得研究对象，这时候，采用抽样方法就不管用了。
我做吸毒者研究，做性工作者研究的时候，虽然 研究对象的数量比铊中毒病患的数量要大得多，
依然无法采用抽样方法。
还有一种特殊情形，假设是教育部委托博士生在做我们的题，
有足够的时间，也有足够的资源，中国大陆高中毕业生的数量， 考上北京大学的数量，也很容易获得，这个时候，就不需要节省了。
如果我们坚持采用抽样方法，坚持节省，就有可能因此而产生误差，
误差我们一再提到过，不过呢，现在还不是讲误差的时候，大家先记住这个概念。
讲了半天，到底什么是抽样呢？下边，我们对这一节的内容做一个小结，小结中
你就知道答案了。抽样就是用代表来代表同类的做法，注意，这不是科学的定义，是操作定义，
这里并没有在抽样两个字的前面加上任何的定语。
如果讲概率抽样，这个定义就不准确了。概率 抽样我们接下来会讨论，这里大家只需要记住
抽样就是用代表来代表同类。之所以要抽样，是为了节省资源，
进而节省成本，也是为了效率，抽样不是无聊的行为，真的是因为资源有限，也因为更有效率。
这一节的内容就到这里，谢谢大家。

---

## 抽样的要素

我们知道了在社会调查与研究中，由于多种因素， 使得研究者不可能，常常也不需要对所有调查对象搜集数据，
而只需要从调查对象的群体中抽取代表来搜集数据，
问题是怎么样抽取才有代表性，代表什么呢？ 为了获得代表的方法，抽样方法，我们先要
有一些基本的约定，这些约定呢，不仅是抽样的基础工作，
也是人们对样本代表性进行评价的基础，这就是抽样的要素。这一节， 我们讲抽样的要素。
抽样的要素，主要是约定性的， 对约定性的东西，我们学习的方法也有不同，以记忆为主。
希望大家分一些时间，讲授中呢，我也尽可能地想办法，让大家容易记。
第一个要素是总体，什么叫总体，社会调查与研究 有具体的调查对象，研究对象，对吗？通俗地说，
所有对象的集合 就是总体。可是什么是对象呢，社会调查与研究的对象与研究问题又关联在一起，
严格地说，总体指的是研究问题指涉对象的集合体， 也就是研究问题涉及的全部对象。
抽象概念听起来总是不那么容易理解，我们还是来看例子。
CFPS的总体，就是中国所有的家庭户。CGSS的总体呢，
就是中国所有的个体。入学机会的地区不平等的总体，
就是某年所有的高中毕业生。听起来满清楚的对吗？ 不过我心里不大有底，这些界定真的很清楚吗？
如果让你马上去操作，你真的觉得
清楚吗？其实，我们还是有不少疑问的，比如说，什么叫中国所有的家庭户，中国所有的个体，
什么叫所有，台湾算不算？香港和澳门算不算？
住在中国的还是有中国户籍的？住在中国的外国人算不算？ 长期出国却依然有着中国户籍的人算不算？
什么叫家庭户？没有生活在一起，户口在一起算不算？生活在一起，
户口不在一起的，算不算？怎么才算是某个地方的家庭户？
户口在甲地，却很少在甲地居住，算不算甲地的家庭户？ 什么叫所有高中毕业生？没有参加高考的算不算？
在没有参加高考的人中，因为非主观原因而没有参加高考的算不算？等等。
大家课后做做练习，慢慢地，对这类问题就会有敏感性了。
第二个要素，研究总体。
研究总体指什么呢？指可操作的研究对象，可及的总体。
我们还是用前面的例子。CFPS我们把总体定义为中国的家庭户，
指有中国户籍的家庭户，指住在一起的，不管户籍是不是在一起的家庭户。
理论上，既然对象是中国所有家庭户， 我们就应该以中国境内所有的家庭户
为研究对象。问题是，我们有资源找到所有的家庭户吗？
这样，在理想与现实之间就出现了冲突。社会调查与研究活动总是会遇到
这样的问题的。我当年的选择是，选择自愿许可条件下的可及的总体。
我选择了二十五个省市自治区的居住家庭户，为什么把其它的省级单位扔掉了呢？
比如说，西藏、青海、宁夏、内蒙、新疆、海南、
港澳台都不在其中，港澳台属于特殊情况，我们可以暂时不管。
其它的六个省级单位为什么不管呢？理由是地广人稀， 调查一个家庭户的成本实在是太高了，我没有那么多的资源，
那么扔掉以后对整体的推论有多大影响呢？
在当时，六个省级单位的总人口占大陆总人口的比例不到百分之五，
二十五个省级单位的总人口呢，已经覆盖了
大陆总人口的百分之九十五，够了，不会影响到推论的大局。
CGSS的研究总体，覆盖了大陆的所有省级单位，却不一定能覆盖所有的个体。
入学机会的地区不平等研究，研究总体就是中国大陆
某年的高中毕业生，与总体是重叠的，问题是，这些界定真的很清楚吗？
以CFPS为例，家庭户指居住在二十五个省级单位内的家庭户吗？
户籍不在本地的算不算？住又是什么意思呢？住多长算是住？ 一个人打工住在本地算是一户吗？
同学们课后继续做一做练习，看还有哪些问题不清楚。
明确了研究总体，接下来要做的就是制定抽样框，又叫抽样总体、框总体。
抽样框，就是从研究总体中获得的用于抽取样本的
研究对象的集合。从确定总体开始，我们再一步一步地 缩小操作范围，总体最大，研究总体呢？比总体要小，
当然有时候，也与总体一样大。现在抽样框可能与研究总体一样大，
也可能，又要小一点。还是用前面的例子，cfps总体是中国所有的家庭户，
研究总体呢，是二十五个省、市、自治区的常住户， CFPS的研究目标是对一个家庭户的综合情况进行调查，
因此呢，家庭户的相对稳定性， 就是确定抽样总体非常重要的参考因素。
有鉴于此，我们选择了常住户。
按照中华人民共和国户籍法的规定和相关的规则， 在一个地方连续居住六个月或以上的家庭户
被叫做常住户，也就是这个家庭户， 会让我们在抽样的时候遇到一些麻烦，比如什么叫户，什么不叫户，
就不是很清楚。CGSS的抽样框呢，则是大陆的常住人口，
入学机会的地区不平等的抽样框呢，则是某年可及的高中毕业生，
抽样框与研究总体是重叠的，与总体呢，也是重叠的。
显然这里又有问题出现了，比如说什么叫常住户，什么叫常住人口。
户籍在本地，工作在外地的算哪呢？偶尔回家又算哪的？ 户籍在外地经常来本地居住的算不算？
集体单位算不算？比如军营、学校、监狱等等，依然请同学们课后做一些练习。
到这里，有些同学可能有点糊涂了，没关系，我们来做一个整理，捋一下三者之间的关系。
从覆盖面和覆盖的对象数量出发，
把总体、研究总体、抽样框放在一起，就会发现总体大于或等于研究总体，
研究总体呢，大于或等于抽样框，抽样框的制作，
是一项专门的技术，在抽样技术部分会有所涉及，不过呢，我们这里讲的不会很详细，
理由是过于详细的技术细节超出了 基础课的范围。现在，假设我们有了抽样框，
抽什么呢？CFPS是要抽家庭户的，CGSS呢，要抽个体，入学机会课题
要抽毕业生，这些不同的对象，我们是否可以有一个概念来概括呢？ 有的，这就是抽样单位。
抽样单位，就是抽样指涉的基本单位，或包括基本单位的单位集合体。
在抽样中呢，就是样本单位。我们来看例子。
CFPS在抽到家庭户之前还要 抽样本区县，样本村居，每一次抽样面对的基本单位
就是抽样单位。同样CGSS在抽到个体之前，还要抽 样本区县，样本村居，样本家庭户，
每一次抽样面对的基本单位呢，也是抽样单位。
这些界定看起来也很清楚，不急，稍后等到进入抽样实践的时候，大家
又会遇到问题的。为此我还是请大家课后做一些练习，用一个例子试一下，
看会遇到怎样的问题。假设我们已经明确了抽样框、抽样单位，现在是不是就可以进入抽样了？
稍等，在操作之前我们依然需要把原则方法弄清楚。
抽样，就是从抽样框抽取样本的过程。听起来很简单对吗？ 同学们可能会反问，有什么困难吗？
有的。抽样之前，我们得知道采用什么样的策略
进行抽样，这就是抽样程序抽样方法的结合。还有呢，采用什么方法抽样。
CFPS和CGSS是大型调查，它的抽样我们会做例子进行讨论，
大家课后呢，可以拿入学机会的课题作为例子来做练习， 除此以外，
同学们最好用自己选定的课题作为例子 来做练习，即使有同学选定的是案例研究的题目，
现在，你也把它修改为抽样调查的题目，练习制定抽样策略和选择抽样方法。
有同学可能马上要问，老师，我的题目怎么改， 既能保证是我的研究兴趣又能够做抽样的练习呢？
原则是，需要用抽样的题目一定是涉及到总体的题目，
具体的建议，请有问题的同学把问题提到研究实践的讨论版上，我们一起来讨论。
一旦我们制定了抽样的策略，选定了抽样的方法，
就可以运用抽样策略和抽样方法抽取样本了。样本是什么，就是从抽样框中运用抽样策略
和抽样方法获取的样本单位的集合，简称样本。
CFPS的样本，就是从二十五个省市自治区
抽取的一百六十个区县样本，从一百六十个区县样本中抽取的
六百四十个村居样本，从六百四十个村居样本中抽取的 一万六千个家庭户样本。
CGSS的样本呢，同样，也是从区县样本
到村居样本，到一万户家庭户样本，再到一万个个体样本。
入学机会课题的样本是什么？是不是高中毕业生样本？ 你自己课题的样本又是什么呢？
下面我们对这一节的内容做一个小节，
同学们首先要明白的是，抽样是对研究问题涉及的总体进行调查，搜集数据的一种方法，
涉及抽样的过程呢，也是一个理清楚搜集数据对象的过程，
需要知道到哪里搜集，找谁搜集数据，
在理解抽样原理，掌握抽样方法之前，我们必须明白抽样涉及的基本要素，总体、
研究总体、抽样总体、抽样单位、抽样策略以及样本，
这是一些基本约定，也是我们之间的共识。有了这些基本的共识，后面的活动才好展开。
这一节的内容就到这里，谢谢大家。

---

## 抽样的逻辑1

了解了什么是抽样；了解了抽样的基本要素；知道抽样的目的是为了提高效率，
也是为了节省成本；知道如果要抽样，就要先界定研究问题指涉的总体、研究总体、 抽样总体，才可以进行抽样。接下来，
我们要讨论抽样会面临的难题以及解决方案——抽样的逻辑。
先讲概率抽样的逻辑，明白概率抽样的逻辑对非概率抽样就可以举一反三了。
在讨论什么是抽样时就已经讨论过，抽样设计研究问题指涉的 对象群体的同质性与异质性。
现在，我们把这个原理运用到具体的案例中来，看看我们会遇到怎样的难题。
继续我们的课题。入学机会的继续不同等研究，
假设中国有三千所有高中毕业生的学校，其中呢 一千二百所处于经济发展水平较高的地区
一千一百所呢，处于经济发展水平中等的地区，剩下的七百所处于经济发展水平较低的地区
地区内部完全没有差异，这是一个理想的情景，现实中是不大可能的事 我们会有怎样的观察呢
地区之间具有高度的异质性，地区的内部呢，具有高度的同质性。
我们假设了地区内部完全没有差异， 就是指地区内高度的同质。
理论上我们每一类地区，我们任选一所中学就能够代表 各自所在的地区。在这样的条件下，
抽样方法就很简单，就是从每一类地区任选一所学校 就可以比较地区之间的差异了
问题是三类地区中的任何一类，内部不可能没有差异
地区内完全没有差异的假设太理想了，在现实中
地区内部，几乎没有一所学校所处的经济发展水平是相同的，即便是北京市的海淀区
北京大学附中和中国人民大学附中都在海淀区，两所学校相差不到一公里，
外在的环境几乎是一样的，可各自真实的经济状态却有很大差异。
这就是由变异性带来的问题。
研究活动要面对的就是同质性条件下的变异性， 这里的同质性指的是一定测量精度下的特征一致性。
比如说，某些地区的经济发展水平比较相近， 假定，我们用百亿元做测量尺度，相互之间可能就差不多。
变异性指什么呢？指不同的个体之间在同一个 变量属性值上具有差异。
比如说，在具有同质性的地区，每一个经济发展水平的测量值都不相同，
变异性的存在给研究活动带来的影响。
我们不能够同一个地区代笔所有的地区， 也不能用一所中学代表一个地区的所有中学。
我们只能假设，在一个足够大的群体中个体的变异性 表现为某种分布，进而呢，个体之间的差异
也表现为某种分布。这样我们就可以选择一定数量的样本， 来理合总体中个体变异性的分布，进而代表总体。
尽管如此，样本群体理合的分布也不可能完全代表总体真实的分布，
用样本代表总体始终会有偏差。
如果从偏差的角度看抽样，那么抽样的原理就是用数量“小”的样本
反应数量“大”的总体的研究特征，可是我们又不能忽视偏差。
这样抽样的基本逻辑就是，用尽量少的样本， 在可接受的误差范围内，来代表总体的研究特征。
注意，我对代表性的一再强调实际上是沿用了last柯西的思想。
柯西曾去美国国会作证， 他反对在美国实施人口普查，认为每十年一次的人口普查，
耗费太多的资源，实在没有必要。在美国，尽管人口普查
的初始用途是为了划分选区，可柯西依然认为
用抽样调查花费很少，也完全可以获得用普查方式
所得到的数据。在柯西看来，用代表性的样本就可以估计总体的研究特征。
因此呢，抽样的基本原则就是满足样本对总体的代表性， 不过代表性并不是三百六十度的代表，
而是研究特征意义上的代表，要对研究的确认，
又要取决于研究问题，可在实践中，抽样要面对的常常不是一个研究问题的特征，
而是多个研究问题的特征，这就给抽样带来了选择性难题。
譬如，我设计的CFPS的基本理论方案。
CFPS的研究问题特征到底是什么呢？一句话。
用个体和家庭层次的变化来反映社会的变迁。
体现在一个嵌套的关系体系中，个体镶嵌在家庭中。
家庭呢，总是和社区关联在一起， 嵌套在社区中。而社区呢，
总是镶嵌在一个更大的社会之中，这就是CFPS的研究问题特征。
个体与家庭之间又如何反应社会的变迁呢？ 我们还得回到个体上来，个体从生到死，都是一个成长的过程。
在这个过程中有一些因素是生赋性的，生来就有的。
而且呢，会影响终生，有一些因素的影响是阶段性的， 可以通过人的努力去改变的。
我们先从左边开始，天赋因素。任何人生下来就携带了天然的禀赋，
受医疗条件、自然环境和家庭环境的影响。
产生的结果就是个体的健康状态、精神健康状态、 身体健康状态，它会影响人的一生。
在青少年时期，天赋、家庭、社区所重要的影响因素，
影响到了人的教育，受教育状态呢作为一个重要的影响因素，被带入人的成年。
在家庭工作的平台上，影响到人的成就，伴随人的整个成年。
作为成年阶段的产出，成就被带入到老年，受家庭福利的影响， 作用于晚年的幸福状态。
这就是CFPS的理论框架，显然这里有多个研究特征的问题。
健康、教育、成就、幸福，至少这四个变量非常重要。
针对这四个变量，什么算是代表性的家伙呢？把这个问题一般化。
就是代表性问题，从例子中我们看到了，代表性指的是
研究特征的代表性，完整的说指的是研究特征变量的代表性。
CFPS要的就是代表性的家庭户， CGSS要的就是代表性的个人，
入学机会的地区不平等课题，要的就是代表性的毕业生。
不管是代表性的家户， 代表性的个人还是代表性的毕业生，问题就在于代表性。
对抽样而言，对代表性的强调也是基于
理论假设的，假设在数量大的条件下，每一个家户、每位个人、每位毕业生 实际上都是一类群体
且不同类型的家户、个人、毕业生
在总体的分布是随机的，这样的话呢，根据随机性原则抽取的样本 就能代表总体，就是代表性样本。
如果总体类研究对象的分布越随机，抽样越随机，那么样本的代表性也就越高。
获得有代表性的样本是抽样努力的方向与目标。
尽管如此，我们还是无法避免误差，样本和总体之间在研究 特征的意义上，有两种可能的关系。
一种呢，前面例子中假设的总体内部完全同质，任何样本与总体之间没有差异。
这种条件下的样本就被称之为“匀值样本”。
可是在研究实践中，样本与总体之间总是有差异的。
即时在随机条件下，尽管每个抽样单位被抽中的概率是相等的。
由样本代表的总体研究特征与总体研究特征之间，总是有差距的。
误差就是样本研究特征与总体研究特征之间的差异。
误差的大小一般而言取决于样本的代表性，在实践中，样本对总体的代表性越好，
误差就越小，否则误差就会越大。
当然跳出抽样活动来看误差，就会发现，有多个影响因素会影响到
样本代表总体的误差，误差的第一个来源是由抽样造成的。
抽样误差就是由抽样环节造成的误差，通常又称之为 “随机误差”。
因为不知道哪个环节会出现误差，即使每一个环节都认真谨慎，
也不知道会在哪出现状况导致误差，随机误差是我们希望尽量避免的误差。
另一类误差具有规律性，主要是由抽样设计造成的，因此又被称之为“系统误差”。
我们举例子，假设希望知道性别与成就之间的关系并严格按照抽样方案
完成的抽样，抽到的样本呢却都是男性的，没有女性。
这就是由抽样方案带来的误差，系统性的误差。
系统误差使我们更希望避免的，
因为一旦出现的系统误差，几乎就没有补救的余地，就像一旦把图纸都弄错了， 盖的房子就极有可能没法再更改。
这就是在抽样中最重要的两个误差来源。
如果依据抽样活动设计的对象来了解误差的来源， 我们会发现第一类容易出现的误差与样本的覆盖性有关，
被称之为“覆盖性误差” ，覆盖性误差就是抽样活动没有正确的覆盖
需要覆盖的总体，要么对总体覆盖过度，要么覆盖不住，过度和不足都会导致误差。
举一个例子，还是我们的课题，假设我们界定的总体为参加高考的高中毕业生，
在抽样中我们把自愿或者是因为其他原因没有参加高考的毕业生
都纳入到了抽样的范围，这就是覆盖过度。
如果我们把复读并参加了高考的学生排除在了抽样的范围， 这就是覆盖不足。第二类误差是选择性偏差，
在设计与执行中，因偏好或者抽样活动 都有可能导致某个特定类型的样本的分布出现问题。
比如说，某一类人群过多或者过少或者缺失。举一个例子， 在CFPS
2011年的抽样中，在浙江省台州市的某个样本县 抽到了一个居委会是样本居委会，在这个样本居委会呢。
有一幢楼是农民工的居住地一共有四层只有一个门。
那么抽样方案， 这就是一个住宅单元，为了弄清楚这撞楼的居住状况，
抽样人员必须进入楼里边一间屋子一间屋子地查看，可是呢楼门只有晚上九点才有人打开。
抽样人员根本没有办法进入。
即使是从窗户外也无法判断楼内的居住格局，拿望远镜都不行，
窗帘拉着呢。在制作抽样框的时候，如果被列入其中的住户 就会出现选择性偏差。
如果这个人群不在抽样框，被选机会就没了。
这就是因抽样导致误差的基本类型。
一类叫覆盖性误差，一类叫选择性误差。
这节的内容还没有结束，我们先休息一会。

---

## 抽样的逻辑2

我们接着前面的内容继续讨论抽样逻辑。
对于抽样设计的人而言， 虽然出现误差是在意料之中的，可误差真的出现的时候，
似乎又很难接受，尽管如此，面对误差，要么接受误差， 到底能接受多大的误差呢？
每一类研究对于误差的可接受范围是有约束的，约束的
条件来自于研究问题的特征，或者研究变量的总体特征值，
比如，我们的研究问题，入学机会的概率通常在千分位，
即一个地区的学生，考入北京大学的机会为千分之几，如果误差在百分位，
就是不可接受的误差。在研究实践中， 通常使用可接受误差的经验值，
例如，可接受百分之三的误差，百分之五的误差，一般而言不超过百分之五，
超过百分之五，估计值的执行区间就会小于百分之九十。
对我们的研究课题而言指的是千分位以上的百分之三到百分之五。
当然，对估计精度的要求尽管与统计推论有密切关系， 更重要的是与可用资源之间有密切的关系。
人、财、物、时间、技术、能力，
都是重要的影响因素。举一个例子，2011年在做
医改满意度调查时，春节期间，贵州北部的一个样本村大雪封山，调查人员根本进不去，
放弃村子的几十个样本就会出现误差，如果不放弃， 又不可能始终等着，此时就必须做出选择。
如果由放弃产生的误差在可接受的范围之内，
那么就可以放弃，如果不得不放弃同时产生的误差又超出了可接受的范围，
就只能遗憾地宣布调查没有成功。这就是为什么说， 社会调查与研究始终会面对遗憾。
尽管如此，面对误差， 我们还有选择，那就是尽量减少误差，
解铃还须系铃人，既然误差是从代表性来的， 无论用什么方法，尽量获得代表性的样本，
就是减少误差最根本的途径。
问题是，如何寻找代表性的样本呢？我们来看一个例子，教材中的例子。
用十个人的收入作为例子，显然在统计上是有错误的，
我们假设这里不是真的十个人，而是一百个人，甚至一千个人中收入有十个类别好了，
每个人的收入状态不一样，男的，女的都有， 且不管男女，只管收入，从零到九都有。
假设在十个人中，只抽取一个样本，有多少种可能呢？
每一个人被抽中的概率是十分之一，十种可能对吗？
每次抽到的样本对总体的代表性都不相同，以平均值为例， 真实的平均值为
4.5美元，我们看估计平均值的点，横轴与4.5美元之间都有差距，没有一个点
是在4.5美元上，可以说完全没有代表性，对吗？ 假设我们增加样本量到2，
每一个人被抽中的概率为十分之二，有四十五种可能对吗，还是以平均值为例，
真实的平均值为4.5美元，我们看估计的平均值的点， 不像样本量为一那个时候的
分散了，集中在真实平均值上的点有五个，是最多的，对吗？
也就是说，代表性在增强。我们进一步增加样本量到三和四，
增加样本量为三时，每一个人被抽中的概率为十分之三，有一百二十种可能，
同样等于真实平均值的估计值也是最多的。同理看右边的图，
样本量为四时，等于真实平均值的估计值更加集中了对吗？ 不仅如此，左右两边的图都显示出
估计值的范围在逐步收敛，对吗？ 进一步地，将样本量增加到五、
六，我们看到了，不仅估计值中等于真实平均值的数量在增加， 估计值的范围也在进一步地收敛，
在样本量为一的时候， 当样本量为六时，估计值的范围已经收敛到2.5到6.5之间了，
与真实平均值之间的差距就更短了， 这就意味着代表性更强了。
呵呵，有点意思了。在一个完全
异质性的总体中，随着样本量的增加，样本对总体特征值的代表性在逐步增强，
误差在逐步缩小，用增加样本量的方式是不是就可以减少误差呢？
如果是，我们是不是可以把所有的对象都纳入？普查，还是有必要啊，
问题是，除了国家，谁会有如此的资源呢？ 还有，既然在总体中存在着同质性，
就没有必要把所有的对象都纳入，用同类代表就具有经济性。
如此，抽样面对的问题就变成了有没有办法在样本量足够大的情况下， 比较逼真地接近于真实值呢？
为了进一步讨论地方便，我们需要了解三个非常重要的概念，第一，
抽样分布。抽样分布，又称统计量分布，指样本估计值的分布，
如果按照给定的样本容量，注意，条件很重要，
用同一种抽样方法反复抽样，每一套样本都 可以计算一个估计值，比如说，均值，前面的例子中，
当样本容量为五时，用简单随机抽样方法抽了二百五十二套样本，
每一套都有一个均值，这就得到了一个估计值的分布，
那么估计值呢，也应该是随机的，也遵从一定的分布，这就是抽样分布。
抽样分布可以用来测量抽样方法的稳定性。
第二个重要的概念，总体分布。
总体，不是说总体有怎样的分布，指的是总体特征值的分布，
总体中研究变量特征值的分布，比如说某个班级的年龄会有一个分布，对吧？
年龄，是我们的研究变量，由每一位同学的年龄构成，在年龄序列上的分布
就是特征值的分布，也叫总体分布，总体分布并不总是可得的，
即使可得，也不满足经济性原则，因此，对样本特征值的了解非常重要。
同样，样本特征值也有一个分布，假定从规模一百人的班级中抽取十位同学作为样本，
这十位同学有一个年龄分布， 问题在哪里呢？回到代表性上来了，
如果说，这十个人的年龄分布与一百个人的年龄分布拟合度越高， 那么就年龄分布而言，
代表性就越高，抽样误差也就越小。
否则，抽样误差就越大，重复一遍，抽样分布， 是估计量的分布，样本分布，则是特征值的分布。
从上面的讨论中我们已经了解到，一方面， 样本量的大小与推论误差的大小有直接的关系，样本量越接近于总体，
推论误差就越小，尽管每一位从事社会调查与研究的人都希望有大样本量，
可是有资源的约束却使我们不得不考虑如何经济地获得
充分代表整体的样本，因此，社会调查与研究的两难就在于如何在资源约束、 经济性和可接受误差之间作出合理的选择。
这一节，既有原理，也有概念，内容比较丰富。下边呢，我们做一个小结。
抽样的基本逻辑，就是运用同质性和异质性的原理，
在了解总体的特征值分布的前提下， 在有限资源的约束下，既要经济有效地用代表推论总体，
又要尽可能地降低推论中的误差，提高代表性， 尽量少花钱多办事，这就是抽样的原则。
听起来似乎抽样是问卷调查的事，其实不是，
实证研究都有抽样问题，几乎所有搜集数据
的过程，都涉及抽样。这一节的内容就到这里，谢谢大家。

---

## 简单随机抽样

慢地，我们从理论、 原理，进入到了又有理论原理，又有操作的部分了。
前两节的内容让我们理解了什么是抽样，以及抽样的基本原理，
抽样面对的难题，那些都是在条件约束下，策略选择问题。
这一节呢，则是原理指导下的操作，
我们将分八段讨论概率抽样，把概率抽样弄明白了，非概率抽样呢，就更容易理解了。
讨论概率抽样，首先要理解概率抽样。
其实前面我们已经提到过了，概率抽样，就是运用等概率原则进行抽样的总称。
等概率原则，就是指总体中每一个研究对象被抽中的概率是相等的，
运用等概率原则进行抽样的方法， 至少有简单随机抽样、系统抽样、
整群抽样、与规模成比例的概率抽样、分层抽样以及隐含的分层抽样、
多阶段混合抽样，这些都运用了等概率原理。
不过需要说明的是，在这些抽样方法中，
实际上有两类，一类呢，是直接抽样，一次抽样，一类呢，则是半截抽样，
没有完成的抽样。到整群为止的前三类，简单随机抽样、系统抽样和整群抽样
都是直接抽样，在某些情况下呢又是末端抽样，可以独立使用。
后三类呢，通常不可以独立地用，要结合前三类来使用。
在详细讨论抽样方法之前，我们先做一个约定， 在前面的讨论中，我们对抽样的对象用研究对象来概括，
其实不一定准确，因为对于抽样的对象不一定就是 研究对象，譬如CGSS的研究对象是
群体，不是个体。为了讨论的方便，我们把用于抽样的对象称之为要素，
对于要素概念，在不同的教材中有不同的用法，有的指抽样过程中每一次抽样面对的对象，
或者抽样中最后一个层级的样本对象， 在我们的课堂中我们要做一个约定，专门指最后一个层级的样本对象。
在一些抽样层级中呢，不一定就是抽样对象，
比如，学校以班级为群的整群抽样，抽样对象是班，样本对象
是样本班的学生，学生就是要素。
我们从简单随机抽样开始， 简单随机抽样是最最基础的抽样方法，也是其它抽样方法的基础。
通常，用在一次性抽样中，有时候呢，也用于多阶段的末端抽样。
如果用在末端抽样中，则意味着总体的要素 与末端抽样单位是一致的，譬如，CFPS的抽样，
末端抽样框为一个村，或者一个居类的所有家庭住址列表，
样本呢，则是家庭住址上的家庭户，如果一个家庭住址有多个家庭户，
就需要进行二次抽样，直到抽到家庭户。
再比如CGSS的抽样，末端抽样框为样本家庭户类
符合要素资格的家庭成员，样本呢，就是个体。
CFPS的总体的要素与抽样单位就不那么一致， 而CGSS的则完全一致，那么在什么条件下可以
使用简单随机抽样呢？通常，如果总体规模不大，
不需要分阶段，总体、研究总体、抽样框三者合一的时候，
还有呢，总体内部的异质性没有大到需要专门处理的程度， 不需要分层，
还有呢，对总体的要素的信息知道不多， 在这样的条件下就可以采用简单随机抽样，
简称sis，在操作之前，我们先了解规范性的操作步骤，第一步，
要制备抽样框，第二步呢，要对要素进行编码，第三步呢，要根据抽样的要求抽取样本。
抽取样本可以使用多种方法，比如，随机数表， 比如，软件。
我们看例子。假设，在一个三十个学生的课堂提问，
我们有两种提问方法，第一种呢，每个人都有被提问到的机会， 只是是否可以有第二次被提问的机会呢？
如果不介意有第二次被提问的机会，那就约定被问过的人 也可以再次被提问，这就是放回抽样。
每个人在每次抽样中被抽中的概率是相等的，不过， 在抽样完成之后，再计算每个人在总体中
被抽到的概率，那却不一定相等。
在小规模总体中这是常发生的现象，在大规模总体的抽样中，
这比较少发生。如果希望没有人被提问两次， 则可以采用另外一种方法，那就是非放回抽样。
由于提问的样本不再被放回总体之中，因此不会有
第二次被提问的概率，问题是，非放回在抽样条件下在每次提问中每个人被问到的概率是相- 等的吗？
我们会发现，越是往后，之前没有被问过的同学 被提问的机会就会越高，似乎违背了等概率原则，
对吗？看来一个三十个人的班级的提问，也是一件很复杂的事情，
做放回抽样吧，抽样结束后每个要素的被选概率 有可能不等，做非放回抽样吧，抽到第二个样本的时候，
每个要素的被选概率就不相等了，怎么办呢，为了保证等概率性， 可以使用工具，比如随机数表进行抽样。
还是三十个人班级提问的例子，先制作抽样框，
第一步，如果在抽选个人之前还有抽样活动，就要确认当前的班级是样本班级，
第二步呢，如果是，就对班级的三十位同学从零到二十九实行顺序编码，
至于按照什么顺序进行编码可以讨论，比如说按学号啊，按座位啊，都行，只要是有规则，
并且保证每一位同学只有一个唯一的编号就行。
第三步呢，选择一个随机数表，大家可以找到很多的随机数表， 我们用教材附录中的随机数表。
在查阅随机数表之前，说出第一个样本的行列位置作为起点。
第四步，在随机数表上找到上面的起点，比如，希望提问十位同学， 那就取一组随机数的固定位置，
十位，也就是零到九，只需要定位 一位数就好，按照事先制定的规则，选中随机数字中的一位，
就是第一个样本，依照事先规定的阅读方向，横向按组阅读，纵向按组阅读
都行，查到下一组数中相同的位置的数，就是第二个样本，依次类推。
我们来看使用随机数表进行抽样的操作吧。这是随机数表的一个截图，
假设，我们事先约定了按纵向阅读，
并在查阅随机数表之前，已经约定了第一个数字的位置，
在第二行，第六个数组的第一个数字， 为第一个样本，也就是六，那么在班级中，编号为六的同学
就是一个样本，编号为一的同学，就是第二个样本， 编号为九的同学呢，就是第三个样本，依次类推。
如果遇到已经抽中的编号，就跳过去，继续阅读抽选，
如果样本量为十二，那么在随机数表中，要选的就不是一位数的编号了，
而是两位数的编号，同样的道理，也可以处理多位数样本的定位。
这样就保证了每一位同学的被选概率是一样的。
在抽样实践中，使用随机数表抽样的例子已经不多了， 因为效率太低，即使用到，也是随机数表的一些变体。
比如说kish表，我们以CGSS的抽样为例，
看看kish表的用法。kish表作为随机抽样方法的一种，通常用在
末端抽样上。末端抽样，就是抽到要素层级的抽样，第一步，制备末端抽样框，
将样本家户所有符合要素资格的成员，按照 规则顺序编号，依据性别也好，年龄也好，逆序也好，顺序也好，
怎么排都行，要求是不重，不漏。
接着就是使用kish表。第二步，拿出事先准备好的kish表，
根据指引，抽取样本，我们来看看具体的操作。按照CGSS对要素的约定，
年满十八岁及以上的人口，都是要素。抽样的约定是不管家里有几个要素， 只抽取其中的一个要素作为样本。
我们把家庭人口数量常见的状态都纳入了考量，
这就是我们在表左列看到的情况，家庭要素从一到五有不同的抽选方案。
比如，家里有四个要素，如果选择a表作为抽选方案，则抽选编号为一的
作为样本，同样，如果选中b1表作为抽样方案，也选择编号为一的
作为样本。如果选择e2表作为抽样方案，则选择编号为四的作为样本。
如果选择f表作为抽样方案，同样，也选择编号为四的作为样本。
有的同学可能会问了，老师，到底选择哪个表作为抽样方案呢？ 是怎么确定的？很简单，操作指南中，就已经说明了
使用方法。有的就是随机选择起始表号，
按照规则继续和循环，有的呢，直接指定了从哪个表号开始，
按照什么规则继续。简单随机抽样还有一个办法也是常用的办法，就是用软件。
常用的统计软件，比如SPSS，不少学校都购买了正版，
操作起来也很简单，先加载数据表，在我们的例子里，
就是零到二十九编号的学生名单，然后呢，在菜单中找到数据，
选择个案，随机个案样本，给一个阈值，零零到二九，随机抽选五个，运行，
就能获得n组由五个样本所组成的样本组来了。
除了SPSS，常用的统计软件都可以进行 简单随机抽样，甚至excel表格都可以进行简单随机抽样。
我们再举例子，Stata，也是常用的软件。
曾经主要使用命令行，新的版本呢，也使用菜单工具了。
以命令行为例，sample n 逗号，count， 就是在所有个案中抽取n个作为样本，
sample n if gender 恒等于 1，count， 就是在满足gender为1的个案中，抽取n个作为样本，
sample n by area， 就是按照地区分类，每类抽取百分之n的地区作为样本，
也可以运用gsample命令，例如，gsample n， 就是在既有的数据集中，抽取n个个案作为样本，
软件的详细使用方法 两个软件的帮助文件指导性都很强，大家看软件的帮助，有一点耐心就好。
就简单随机抽样而言我要强调两点，第一，简单随机抽样是不得已的办法，
不是最先选用的办法，什么情况下 才用它呢？只有在总体的信息所知甚少的情况下，
才用它。简单随机抽样就讲到这里，谢谢大家。

---

## 系统抽样、分层抽样、整群抽样

简单随机抽样尽管独立运用于抽样不多， 但却是原理性的，
在许多抽样方案的末端抽样中都会用到，请大家一定要熟悉，不仅仅是熟悉怎么抽，更重要的- 是要熟悉原理。
同样，在许多抽样方案的末端抽样中， 也会用到的简单抽样还有系统抽样和整群抽样。
系统抽样和整群抽样也是一次性的抽样方法。
我们现在看系统抽样，系统抽样也是简单抽样方法中的一种。
通常也是用于一次性的抽样，比如对一个班级几十个要素的抽样。
也用于多阶段或者多层抽样的末端抽样。
简单地说，用于总体要素与抽样对象一致条件下。
系统抽样的应用情景与简单随机抽样一样。
通常规模也不大，也是总体、研究总体、抽样总体， 三者合一，要素之间在研究变量上的异质性
或者同质性，也没有大到需要专门处理的程度，不需要 分层。
与简单随机抽样的条件不同的地方在于，
除了不需要分层以外，还要求要素的特征在排列中没有周期性的变化。
举一个例子，假设一个班级有50个人，
男生25位，女生25位，在排列时，每位男生的后面或者前面都是女生。
同样的道理，每一位女生的前面或者后面都是男生，这样男生跟女生之间的排列就是周期性- 的排列。
之所以要求要素的排列不能有周期性的变化， 是因为系统抽样又叫等距抽样。
万一要素的排列的周期，与抽样距吻合了。
抽到的就是一类样本。
这就是选择性偏差由抽样选择带来的误差。
系统抽样的抽样步骤也比较简单，第一也是要界定抽样框。
第二把抽样框的要素按照规则进行编码，在编码中可以运用任何已知的信息。
万一什么信息都没有，那就采用顺序编码。
第三，用要素的总体数除以样本数，得到抽样距。
第四选择任何一个随机起点，依照抽样距或者顺序抽样或者循环抽样。
接着我们有两个图示给大家演示。
还有一点需要注意，如果抽样距有小数点， 那就取整数四舍五入。
我们来看操作方法，抽样前要制备抽样框，以班级
抽样为例。第一步把班内所有的的学生名单按照一定的规则进行排列， 这里我们假设是按照学号在排列。
第二步把排列好的学号，从1开始顺序编号。
第三步假设我们要在16位学生中， 抽出三个样本 ，抽样距为5，样板量3。
第四步假设我们把要素排列成一个循环圈，
选择一个随机起点为编号8，编号8就是第一个样本。
顺时针数第5个也就是编号11，就是第二个样本，以此类推。
在排列要素的时候，我们不仅可以排列成循环圈，也可以排列 为直线。
同样随机起点为编号8，顺序数编号11为第二个样本。
数到16不够测量距了怎么办？ 回头接着数到编号2，就是第三个样本。
从这个例子我们看到，系统抽样的框不能太大。
太大了就很费事，仅就要素编号 就比较费事，第二要素的排列特征不能呈现周期性变化。
假设有这样的情形，我们要在一个年级尝试某种教学法对学生学习效果的影响。
再假设一个年级有16个班，班与班之间没有特别的差异。
这个时候，我们知道，总体、研究总体、抽样总体是一个年级所有的学生。
可是就教学法而言，我们不能在一个班中让 某些同学面对A教学法，让某些同学面对B教学法。
在这种条件下的抽样，就是把一个班级所有的学生作为样本 ，整群抽样，
就是把抽中的抽样单位的所有要素，作为样本的抽样。
对整群抽样方法的应用，通常 不作为独立抽样的方法使用，而是用于多阶段、
多层次抽样的末端，把末端抽样单位 包含的所有要素都作为样本
，那么在什么情境下才会用到整群抽样呢？ 通常是群内具有异质性，不过群内的
异质性还没有 还没有大到需要专门处理的程度。不仅如此， 群之间的差异，也没有大到需要专门处理的程度。
以刚才的抽样为例，事实上， 我用一个班内部的异质性代表了一个年级总体的异质性。
如果要素之间的关系满足上述条件，那么整群抽样就是节约资源的有效方式。
以CFPS为例，根据抽样原则 每个样本区或者县要抽取100个家庭户作为样本。
那么这100个家庭户怎么抽呢？ 是把整个区或者县所有的家庭混在一起抽还是先抽到乡镇
乡镇、街道，把样本乡镇、样本街道的所有家庭户混在一起抽呢？ 根据中国的实际情况，在某些偏远的乡村地区 ，
一个县域的府内可能与东部某些省域的范围差不多大 即使是乡镇范围也不小，如果样本家庭户很分散
调查成本将会极其高的，在这样条件下，我们假设乡镇之间具有异质性。
乡镇内部的村庄之间具有相似性，同样村庄内的家庭户之间又有一定的异质性或者相似性。
在现实中，这样的假设是成立的，对吧？ 这样CFPS的抽样策略是，在样本县直接抽到村庄。
在村庄样本采用了近似于整群抽样的方法。
从例子中我们知道，分群是保证抽样 满足代表型的重要环节，在自备抽样框的时候，
还是以教学法为例，抽取群单位的时候，在操作上采用了简单随机抽样方法，对吧？
之所以这么抽，是我们假设了班与班之间特征的差异不大，
因此分群就非常重要。分群的基本原则是：
在选择研究变量，或者与研究变量高度相关的辅助变量时，
让它在群间具有相似性，同质性，在群内具有异质性。
与实验分组的条件差不多 ，当然通常很难完全做到。
在自然分组的情况下，只要群间、群内有这样的特征就够了。
如果群内同质群间非常异质，那就不适合用整群抽样了，好了。
分群的方法，在调查实践中其实很简单，尽量利用自然的群。
比如说前面例子中的班级，每个班级同学的学习成绩有一个分布，在班与班之间，具有相似性。
相似的可以用做分群标准的辅助变量，比如说 行政区划、组织、行业、班级、年龄 、性别等等之类。
在分群中有一点需要注意，群的规模不宜过大，否则就有可能出现内部同质性。
影响抽样的效率，操作起来也很麻烦，什么是抽样效率后面会讲。
到这为止，我们讲的都是一次性抽样，简单随机抽样、系统抽样、整群抽样。
系统抽样和整群抽样就讲到这里 ，谢谢大家。


---

## 比例抽样

大家还记得我们在讨论抽样之初就做过的一个假设？ 假设总体的每一个要素都一样。
如果希望了解总体某个研究变量的情况，只需要对 只需要对一个样本进行测量，就可以知道总体的情况了对吗？
在现实中，这种假设完全是不可能的。
同样不可能的是，总体的每一个要素在研究变量上是不同的。举一个例子，以年齡为例,
在中国大陆同年同月同日同时同分同秒 出生的人可能不多，也有，不过呢？同一年出生的人就多了。
从二十世纪的六十年代每一年都以千万计。
正是同质性与异质性的并存 让抽样变得麻烦起来。假设，变异的复杂性与人群的规模是有关的。
比如说，人群的年齡分布，职业分布,受教育程度分布，收入分布，观点的分布
可能都与人群规模有关，那怎么抽样呢？ 这就要用到与人口规模成比例的概率抽样，也就是PPS抽样了。
运用PPS抽样主要是因为异质性的影响。如果总体的要素之间
在研究变量上有异质性，而且呢，不同规模要素群体之间异质性的分布不是随机的。
在这样的条件下，就要考虑把规模因素纳入抽样的考量了。
我们举例子，比如说家庭收入。
如果百分之十的人群占有了所有家庭收入的百分之九十，另外百分之九十的家庭呢，只占有百- 分之十。
这就是一个不随机的异质性分布。
在这样的条件下，如果采用简单随机抽样，
就可能造成其他的偏差。要么呢？抽到百分之十的人，要么抽不到。
假设有一百户，要抽十分样本，理论上前百分之十的 样本为一，后百分之九十的样本量为九。
这样才能正确地估计总体。
如果采用简单随机抽样，极有可能抽到零个前百分之十， 十个后百分之九十。当然也有可能是其他的情况。
用这样的样本集来估计总体， 就会比总体的真值要低，由此产生误差。
这是我们知道了总体分布，进而也知道了抽样误差。
一般情况下，我们并不知道总体分布，却可能知道异质性分布的不随机性。
这时候就不能采用简单随机抽样方法。PPS抽样是其中的一个可行的选择。
PPS抽样理论上运用了等概率原理。
就是希望让每一个抽样单位被抽中的概率 与抽样单位的规模成比例。听起来似乎比较难理解。
我们用例子吧，我们讲一个实在的例子，大家能感受到的例子。假设，在海淀区西北旺乡
有一百个社区，四万户， 根据抽样要求呢？要抽取十个社区，也就是百分之十，也就十分之一的
样本社区，每个社区呢，抽取二十户，一共抽二百户。
该怎么抽呢？为了便于理解，假设， 要试着针对A
B两个社区抽样， 并且同时假设A社区有两千户，B社区只有五百户。
还有更小的或者更大的，我们先只针对这两个社区。
在社区层次来看，A社区的总户数占西北旺乡的总户数的
比例为四万分之两千，0.05。
也就是A社区被抽中的概率为0.05。
同样的道理，B社区被抽中的概率为四万分之五百， 为0.0125。
B社区被抽中的概率只有A社区的四分之一。第一阶段的被选概率是按照
与规模的比例来的。这就与规模成比例。可是到目前为止我们还需要知道
社区家户的被选概率。我们给定的是每个社区只抽二十户。
那么A社区家户的被选概率就是两千分之二十，0.01。
B社区家户的被选概率呢为五百分之二十，0.04。
正好是A社区的四倍。这样从整个西北旺乡来看
每个家户的被选概率为每个社区的被选概率与社区内每个家户有被选概率的乘积。
那么呢？A社区家庭户在西北旺乡的被选概率就是 0.05乘0.01等于0.0005。
B社区家庭户的被选概率是
0.0125乘0.04也等于0.0005。
两个相同。这样满足了等概率原则。其实也与理论值一致。
理论上社区的被选概率为十分之一，
家庭户的被选概率为0.0005。两者的乘积就是总体每个家户的被选概率，0.0005。
与每个社区家户的被选概率是一致的。
从这里我们看到，第一，PPS抽样，常常会考虑抽样面对的现实，
常常是多阶段抽样，不是抽一回。
第二呢？有些信息，抽样时并不知道，常常要步步为营，充分利用已经知道的信息。
第三呢？每一个阶段的抽样概率不一定相等。
第四呢？总的原则是总体要素的被选概率一定要相等。
这就是PPS抽样的核心。
具体到我们的例子，我们已经给定了每一个社区的样本量及每个社区二十户， 那么，每个阶段的抽样概率在这里做什么用呢？
用于加权，用做权数，以保证 在西北旺乡这个层面让每个家庭的被选概率相等。
有同学可能会指出，既然事先已经知道了每个社区的家庭户数
是不是可以采用更加直接的方法，比如用总体要素的被选概率乘以要素的数量， 这就是样本量啦。
还是以西北旺乡为例，我们知道总体要素的被选概率为0.0005，
那么A社区的样本数就等于2000乘0.0005等于一户， B社区就没有样本了，对吗？
这样就会造成更大的误差，这就是为什么事先要对样本社区指定样本的户数，
分两个阶段来抽样，和采用事后加权的方法呢？以保证等概率性。
那么在什么条件下需要或者可以使用PPS抽样呢？ 基本的条件是具有抽样大小规模的辅助变量，比如
规模量度，又叫规模度量。通常拿什么来做规模量度呢？
就是代表规模的，比如说社区的家庭户数。
我们常会举例子，如果按照与抽样单位的家庭户规模成比例抽样，那么，记载各个抽样单位家- 庭数的变量
就是辅助的量度。当然做为规模量度的变量可以有多个，
最常用的方法是依据研究变量相关程度来挑选。
影响因素还有获取资料的难易程度，可靠程度。
PPS抽样基本用在两阶段多阶段抽样中，每一阶段使用的
规模量度一定要相同。在我们的例子中，第一阶段是社区抽样，
被选概率计算还是采用了家庭户数。第二阶段呢？是家庭户抽样， 备选概率的计算也采用了家庭户数。
强调一遍，PPS抽样是一次抽样多个阶段的方法，原则
是满足等概率原则，条件是总体要素在研究变量上的异质性 与要素的规模成正相关。
甚至在这个意义上可以被看作是一次一阶段抽样的扩展，
一次性抽样的扩展。PPS抽样也可以运用软件工具执行，比如Stata工具， 就可以用gsample。
gsample是分正式的一个ADO模块，可以运用多种抽样需求。
除了运用gsample命令，也可以使用samplepps。
这也是Stata中的一个第三方抽样模块。
对计算机软件的详细运用， 在这门课中，我们只是给大家提供线索，指路，如果希望
熟练地运用相关软件，这需要修读专门的课程，或者详细地阅读 软件手册。与规模成比例的概率抽样就讲到

---

## 分层抽样

如果我们要研究学校的教育模式对学生能力的影响，比如北京大学和清华大学的学生，
就有很不一样的能力。
显然，不同院系内部具有某种同质性，院系之间呢，却具有异质性。
假设，院系的规模大致相若，则规模就不是影响估计误差的重要来源了。
在这样的条件下，异质性就变成了影响估计误差的重要来源。
也就是说，从总体上看，要素之间有比较大的差异性，
如果异质性是随机分布的，我们依然可以采用简单随机抽样方法，但如果异质性分布不是- 随机的，
采用简单随机抽样方法显然就会带来较大的误差， 那我们就不得不对异质性做专门的处理，其中，
分层是减少因异质性的不随机分布而带来误差的重要方法。
还是我们的例子，大学的教育模式对学生能力的影响。
显然不同的院系有不同的影响，还有呢，不同的年级也有 不同的影响。从经验上看，能力的变化受时间和院系
的影响，换句话说，每个院系有自己的文化，学生能力的变化 和形成更多地是随时间，受院系文化影响的过程。
这样我们就可以根据院系随时间的变化看能力有怎样的变化，
这就是分层。在继续下边的讨论之前，我们要澄清一个误会，分层的层有时候不一定是等级，- 而是类别，
是把一个总体、研究总体划分为几个内部具有同质性的总体、
研究总体，在每个总体中呢，或采用一致的抽样框，
或采用不一致的抽样框，千万不要误会分层就是分等级，大多数
情况下是分类别。了解了分层的原理，那么到底怎么样分层呢？
分层的步骤很简单，第一，要分层就要把研究总体按照 研究特征变量，常见的比如说年龄啊，性别呀，
受教育程度来进行分层，在我们的例子中没有这些常见变量，我们只讨论教育模式对学生能力- 的影响，
现实中，有社科、理工、人文，还有院系、年级
和类别，用这些来分层。假设为了简单起见，我们只区分文和理两个大类的院系，
第二，在每一层采用合适的方法来抽样， 比如说简单随机抽样或者等距抽样、整群抽样，
等比例或者不等比例的抽样等等，甚至pps抽样都行。
比如，鉴于每一个班的内部具有异质性，可以采用整群抽样， 我们知道学生有文理两类的内部的差异性，
分层的时候已经区分为两类了，从院系
到班，可以采用任何简单抽样的方法，从班抽到学生呢，就可以采用整群抽样的办法。
第三，把每个层的样本合起来加总，
就是用来对总体进行推论的样本，把文和理两类样本加起来，就是一所学校的样本。
如果文理之间学生的数量相差的太大，也可以考虑按学生数量的比例分配样本。
那么在什么条件下可以采用分层抽样或者需要采用分层抽样呢？
基本的条件是对研究总体同质性程度有了解， 知道总体的同质性、异质性如何，
通常，总体在研究变量上的同质性越高，对分层的要求就越低。
还是以学校教育对学生能力的影响为例，这里，研究变量
就是学生能力，我们知道文理两科的学生在各自的内部具有同质性，
相互之间呢，又有异质性，至少我们要区分两个层。如果说，在文科内部，还有人文与社- 科之分，
在理科内部呢，还有理科与工科之分，那就要看异质性的程度是不是大到了
必须分层的程度。通常在研究变量上同质性程度越高，
对分层的需求就越低。除了对总体的同质性要求了解，
对于研究变量也要有了解，比如说，在文科中，学生 的能力可能是想象力，在理科中呢，学生的能力可能偏重逻辑能力，
两者可能有所不同，可是难道理科生就不需要想象力了吗？ 不一定。这些都需要讨论，需要弄清楚。
对研究变量了解越充分，采用合适的分层方式，就越有利于
降低抽样误差。抽样误差是我们尽量尽量要避免的误差。
假设已经具备了分层的条件，那么依据哪些变量来分层呢？
分层依据的变量通常与研究目标有关，与研究变量有关系，
比如说，老年服务需求研究，我们的研究变量是服务需求，
与服务需求相关的变量有年龄、性别、失能状态、健康状态、子女状态。
除了与这些具体的变量有关以外，还有一个重要的变量， 那就是老年群体的社会经济地位。
假设，研究总体为北京市的老年人口，年龄六十岁以上的老年人口，
大家会认为老人们的服务需求具有异质性吗？ 显然社会经济地位对服务需求的影响极大，
省部级退休干部与延庆县山里的老人对服务需求显然不同， 与退休的教授、副教授、研究员、副研究员、医生等等，
对服务的需求显然也不相同。在总体中，这三类人群 就需要作为三个层。
在抽样设计中，研究目的越复杂， 分层变量越多，要区分的层数也就越多，误差的来源可能也会越多。
实践中，希望尽可能地选取主要的分层变量，因为分层越多，看起来越精准，
事实上不可控的因素会越多，可能让抽样误差更大。
在抽样实践中， 有些分层明显，有一些分层则不太明显，有的分层不明显，
有的分层不明显，可能实际上还携带着层变量的分层，我们称之为内隐的分层 或者叫隐含的分层。
还是前面的例子，学生教育模式对学生能力的影响，以北京大学为例，我们知道有的院系一个- 年级有多个班，
比如信息科学技术学院， 有的呢，只有一个班，比如社会学系。如果有多个班的学院用平均能力对班进行排序，
然后呢，再抽取班级样本，则抽到的班样本不仅携带了院系信息， 也携带了能力信息。
经验上，我们的例子中，不仅按文理院系在分层，也在按照
能力进行分层，只是按能力分层被隐含在了按文理院系分层之中，对吗？
知道了什么是分层抽样，以及依据什么变量分层，
还要知道在什么情境下才需要分层以及如何分层，我们先讨论在什么情境下需要分层。
大家需要特别注意的是分层抽样通常不会独立使用，
通常用来构造子抽样框、子总体，它不是独立抽样的方法，
也不是末端抽样的方法，如果总体的异质性很大，比如文理科，那就需要分类处理， 用分类的方式分层，
通常，用于平行的异质性的子总体。比如说，大学里的院系，
院系之间是平行的，不是层级关系，强调一遍，分层不一定就是分等级，
更多的情况下是分类别，当然也有分等级的时候，也指层级关系，比如说同一个院系的不同年- 级之间是垂直的序列关系，
也叫层， 我们来看具体例子。
CGSS的分层有些特点，首先它把中国大陆的个体按照居住地属性 平行区分为了两大类，一类呢，是必选层，一类呢，是抽选层。
必选层，名称容易误解，指的是必须有样本的城市，
城市，抽选层呢，是抽到了就有样本，没有抽到就没有样本的省、市、自治区，
至于哪些层是必须要有样本，哪些需要通过抽样决定是否有样本，
大家可以通过百度搜索工具找到CGSS的抽样方案来看看， 表格中的抽样单位
我们先不管，讲到多阶段抽样的时候再讲，我们只需要知道每一个阶段的抽样单位都是分层- 产生的。
分层产生的。那么，到底怎么分层呢？ 我有一个简单的建议不是标准哈，以我自己的研究为例，以CFPS为例，
通过百度搜索大家也能找到CFPS的抽样方案，分层依据的是研究主题的主要变量，
CFPS的研究主题是个体的生命历程与社会变迁之间的关系， 家庭是个体生命历程的载体，我们要的是，
代表性家庭户，目的是降低抽样误差，
抽样目标就是获得能代表中国大陆家庭的样本家户，
影响因素呢，依据同质性原理， 具有相似社会经济地位的家庭户，家庭环境具有相似性，
因此，抽样要考虑家庭户的社会经济地位。
抽样策略，指定抽样策略有两个依据，国家层面可推论，典型省市可推论，
因此呢我们区分了大省样本和小省样本， 大省样本可以在省级作推论，小省样本只能在国家层面作推论。
回到我们的课题，入学机会的地区不平等研究，
如果希望在国家层面作推论就不需要考虑是否可以在地区层面作推论。
作推论。假设已经分好层了，怎么在各层次去分配样本呢？
样本量的分配有两种基本的方法， 第一种，等比例分配。就是让各层的样本量与要素的规模成比例，
在需要保证不同规模的要素都有样本入选时，这是
这是最常用的分配样本量的办法，如果某个要素群体规模很大，
按照比例分配样本量呢，就会使它的样本量很大， 进而产生浪费，这时候就可以依据经验或者既有的研究结论减少
这个群体的样本量，这样自然就形成了不等比例的抽样。
灵活运用等比例和不等比例的抽样， 也是提高抽样效率和减少误差的有效途径。
怎么分层呢？
我们看一下CFPS的分层，第一个层，其实只产生了两个子抽样框， 形式化的层，是什么？
我们区分了大省和小省，大省一共有五个，在大省层中 我们又区分了两层，辽宁、甘肃、河南、广东，
各为一个抽样框，但遵循相同的抽样方法， 大省中还有上海，上海为一个独立的抽样框，实际上，
这五个省是各自为一个独立的抽样框，其中呢，有四个省的抽样策略
是一样的，另外的二十个省市自治区是一个抽样框。
这是第一层，我们区分了大省小省。我们再看第二层次的分层，
以二十个小省为例，产出了初级抽样单位，二十个 二十个省级行政区，按照人均社会经济指标降序排列，
在每一个省级行政区内，以省会开始，
地级市按照人均GDP指标降序排列，在地级市内呢，则区分三个层，
区、县级市和县，在每一个层内呢，按照区、县级市、
县的顺序以人均GDP降序排列，保证城市属性越强的越排在排序的前面。
这里就隐含了城乡属性的分层， 抽到的样本县、区，就是我们的PSU，初级抽样单位，
在多阶段混合抽样中我们会讲到这个概念。按照如此分层抽取到的PSU，
既有发达的，也有不发达的，既有城市，也有县，
人多的地区有样本，人少的地区也有样本，这样的抽样是有智慧的，
调查数据也表明，CFPS的抽样就主要研究变量而言， 具有很好的代表性，这就是分层抽样，
分层，帮你区分异质性，如果总体有极大的异质性，就一定要区别对待，
否则就会出现穷人代表富人，富人代表穷人的混乱状态，
分层抽样就讲到这里，谢谢大家。


---

## 多阶段抽样

对于抽样方法的熟悉，我们从简单随机抽样开始，如果总体规模不大， 要素在研究变量上的异质性分布具有随机性，则
我们可以采用简单随机抽样、系统抽样，如果可以分群，且不同群之间的异质性不大，
群内的异质性对总体具有代表性，就可以采用整群抽样。
如果总体规模比较大，总体要素的异质性也比较大，且与不同特征群体的规模有关，
那么至少要采用两个阶段的抽样，并且采用与群体规模成比例的概率抽样。
如果总体规模比较大，总体要素的异质性也比较大，且与不同特征
群体的规模无关，研究变量在要素中呈现出某种非随机的分布，则需要
采用分层抽样，把具有相似特征的群体作为一个层，单独处理。
上面的这些如果，都是非常理想的情形，在抽样实践中，常常会遇到更加复杂的情况，
如果遇到搜集数据的范围非常大，要素的异质性分布也很复杂，那么采用上述任何一种方法
都不足以解决抽样问题，以CGSS为例，大家还记得CGSS的要素是什么？
是样本家庭中年满18岁或以上的个体，对吗？假设研究者希望一次直接抽到个体，
需要什么样的条件？对呀，就需要编制一份有18岁或以上中国常住人口的抽样框，
一个差不多有10亿人口的列表，这是不可能的， 最近两次人口普查的人数都有千万级别的误差，
想编制这样的一个人口列表完全没有可能，在这样的需求面前，我们怎么办？
我们可以综合运用已经学习过的抽样方法，分阶段解决抽样遇到的难题。
还是以CGSS为例，先找容易界定的边界，容易操作的可以编制抽样框的层级。
我们知道中国的人口绝大多数都是以家庭为组织单位的，那直接操作家庭可以吗？
不可以，家庭数也太多了，中国大陆有4亿多个家庭，还是太大，
我们也知道家庭总是聚集为社区的，那直接操作社区可以吗？ 也不可以，中国大陆的社区也有百万之多，还是太多，
我们还知道社区受乡镇或者街道的管理；
乡镇或街道呢，又受区或者县的管理；区和县呢，又受省、市、自治区的管理；
到省、市、自治区这一个层级，数量就差不多了，就可以操作了。
如此，我们可以从最容易操作的层面开始，
编制下一个层级的抽样框，每一个阶段一个抽样框，逐阶段地推进， 直到抽到要素层级的样本。
由于每一个阶段总体要素的异质性不同，准确地说，影响要素
异质性的因素不同，因此呢，在多阶段抽样的每个阶段， 采用的抽样方法也不一定相同。
还是以CGSS 2010年的调查为例，CGSS的第一阶段抽样采用了分层抽样，
在抽样之前，区分了两类总体， 一类是必须调查的层，被称之为必选层，一类呢，为选择调查的层，
对此设计者解释说，对必选层，选择街道作为初级抽样单位，
可以细化抽样方，使得样本点相对分散，有利于总体 信息的采集，避免由于抽样框过粗而导致样本有偏。
对于抽选层呢，全国区、县级市、县的数量较多， 以其作为初级抽样单位比较合适，用我们的话来说，
作为必选层的发达的城镇，异质性较强，需要让 样本点分布相对分散，以取得对异质性的足够体现。
作为抽选层的不发达城镇、乡村， 同质性大于异质性，可以采用要素规模更大的区、县作为初级抽样单位。
第二阶段，抽到了村居，采用PPS抽样。
第三阶段，抽到了家户，采用了简单随机抽样， 末端抽样，抽到个体，要素，采用了Kish表抽样。
这就是CGSS 2010年的抽样方案中的
抽样单位列表。在CGSS的抽样方案中， 末端抽样是有瑕疵的，我们就不详细讨论了。
尽管不同阶段采用了不同的抽样方法，
目的还是希望通过统计加权，在保证等概率原则的基础上，能更好地代表总体， 降低误差。
如果是多阶段混合抽样，我们一定会遇到一些概念，其实刚才就
已经遇到过了，在多阶段抽样中，每一个阶段的抽样单位是不一样的，
为此呢，在同行中有一些约定，把第一阶段抽样的单位叫做初级抽样单位，PSU。
多阶段抽样的第一阶段抽样通常要求 抽样对象的数量是这一阶段样本量的3倍或以上，
否则呢，就需要降低抽样单位的层级，举例子，CFPS 2010年的抽样， CFPS
2010抽样也区分了两类总体， 第一类总体是可以独立在省级城市进行推论的总体，被称之为大省。
第二类总体，是只可以在中国大陆层面进行推论的总体，被称之为小省总体。
这里我们以大省总体为例， 针对大省抽样的PSU，是县、区这样一个层级，城市为区，乡村为县。
抽样设计是每个大省呢，要抽16个区县样本，
因此理论上，抽样框至少应该有48个区县， 当时，上海市总共只有18个区县，为此呢，我们不得
不降低抽样层级，到街道一级，街道的数量就多了。
同样，CFPS也采用了与要素规模成比例的概率抽样方法， 上海，就是单独的一个层，这就是初级抽样单位。
在一个抽样对象有限的抽样框中，到底抽多少个PSU合适呢？
这个阶段的抽样还是服务于末端抽样的，要让要素层级的样本在总体上具有代表性对吗？
因此这个阶段的抽样主要考虑的是影响要素层级样本异质性的因素，
如果初级抽样框中，对要素异质性影响的因素多，
需要的PSU就多，同时呢，还需要考虑的因素是费用， 大家要注意，多抽一个PSU，费用就增加不少，
在有限的经费条件下，如果异质性程度加大，就要 尽量多抽PSU，同时呢，也要注意钱够不够。
我的经验是，如果初级抽样框为中国的区县单位，
PSU的数量与县级单位的比例一般不要超过50， 假设现在还有2900个县级单位，
如果希望代表中国大陆，则最少要抽58个 PSU，像CFPS的PSU，就有160个区县，
CGSS的PSU就有164个区县，160相当于理论值的3倍， 主要是希望能够覆盖异质性。
我们再看次一级的抽样单位，第二级 次级抽样单位，SSU。如果总体范围很大，
通常会多余两个阶段的抽样，如果有第二次抽样，那么用于第二次抽样的对象
就是次级抽样单位。为什么要抽两次？有两个影响因素，第一，规模，第二，异质性。
以CFPS的大省总体为例， 设计上在每个PSU中要抽4个村居，
为什么只抽4个村居就够了？是因为抽取PSU的时候，已经把异质性问题作为基本因素考- 虑过了，
在PSU内，异质性的问题开始变小， 基本上只有城乡之间存在差异，4个也就够了。除此以外，还有费用问题，
在一个县域范围内的调查费用，如果样本在地理位置上很分散，
那是非常耗费资源的，这样呢，每一个大省抽取16乘4，共64个SSU。
上海是一个独立的层还记得吗？为了保证大省之间具有可比性，
保证上海的SSU也等于64，上海的PSU就被设置为了32。
我们强调的是覆盖内部异质性，在上海，每个PSU只抽
两个村居，也就是32乘2等于64，总的SSU的数量 与其他大省一致。
在抽样实践中，还有具体的问题，比如有些村居的规模很大，有些村居的规模很小， 为了保证SSU的可比性，
在制作抽样框的时候，对过大的村居要拆分，对过小的村居呢，要合并，
让每一个村居的规模具有可比性。与PSU一样， 对于次级抽样单位，也有样本规模的问题，
同样需要考虑的因素是考虑异质性的程度，当然也要考虑费用，
还要考虑的是根据经验，越接近于末端抽样，越需要考虑实地调查的费用，
一个县，比如北京市昌平区是一个PSU， 如果把SSU覆盖昌平区的所有街道、乡镇，
旅行的费用就非常高，值不值就要考量了。
经验上，一个PSU至少要抽2个SSU， 也不宜过多，最多也就20个，
20个就已经非常多了，多到20个SSU的时候就意味着要访问地理上不同的20个点， 成本非常高。
以CFPS为例，考虑到区、县内的同质性，我们就做了4个SSU，上海2个，
这就是次级抽样单位。最后一级，也就是末端抽样单位，USU，
有同学可能会问：“老师，有没有三级抽样单位呢？四级抽样单位呀？” 不是没有，是看有没有需要，如果有需要，
其抽样原则和方法与PSU和SSU一样， 我们就不重复了。末端抽样，是指抽到调查对象，抽到要素的那个阶段，
比如说CFPS，末端抽样就是在村居内抽到家庭户。
CGSS就不一样，CGSS呢，是在样本户中抽到个人，
我们的课题可能就是抽到地市级所有的高中毕业班， 经验上来讲，末端抽样通常采用简单易行的抽样方法，因为
大多数情况下，末端抽样通常不是由研究人员去抽，而是由 操作人员去抽，有时候呢，还会以数据的搜集活动在一起，
在时间上有一定的紧迫性，比如说像CGSS的末端抽样，
就是由调查员去抽取的。一般来讲，与上一层级的抽样比较，末端抽样方的对象
有一些同质性。为什么要采用多阶段混合抽样呢？
主要是希望在便利性、代表性上达成一个平衡，考虑的还是代表性问题，运用多个阶段来实现- 代表性。
回顾一下抽样的核心，就是希望用尽量少的样本，
尽量准确、精确地来拟合总体研究变量特征的分布，经验上来讲， 不管在哪个阶段抽多少样本，怎么抽，
依据的还是第一，等概率原则，每个对象的备选概率相等。
PPS抽样是把多个阶段的备选概率结合在一起来考量的，
同时呢，还要考虑到运用已有的信息，进行同质性和异质性的判断， 这个是非常重要的。阶段的划分和样本量的确定，还要考虑
经济性，以及对异质性的覆盖，异质性大的，要多抽，同质性大的，要少抽。
多阶段混合抽样，实际上是对各种抽样方法的应用。
关于多阶段抽样，就讲到这里。

---

## 抽样误差

我们知道用样本估计总体总是会有误差的，那么抽样活动产生的误差是唯一的误差来源吗？
如果不是，在所有误差来源中，抽样误差又会有怎样的影响呢？
为此我们首先要知道用样本对总体进行推论时会遇到哪些误差来源。
从经验中我们发现，如果确定用抽样方法搜集数据，那么从一开始，
就会有误差来源。如果按照研究工作的时序来排列，第一个来源是由研究者带来的误差。
理论假设不好，
概念界定不清，对样本要求不明确，既会 造成系统性误差，也会为随机误差的产生提供机会。
第二个来源呢，在设计阶段，由设计者带来的误差， 比如测量工具选的不对，实施策略选的不对，
抽样设计也有问题，同样也会造成系统误差，也会为随机误差的产生提供条件。
第三个来源，在抽样阶段由抽样员带来的误差。
假设前面的所有工作做得都很好，如果末端抽样框的界定不明确，
抽样过程监管也不明确，就有可能产生随机性误差。
第四个阶段，在访问阶段由访问员带来的误差。
假设前面的一切工作都做得不错，如果访员作弊、 作假，轻易地接受拒访，诱导性提问，不规范的提问，
也会造成随机误差、应答误差，甚至系统误差。
第五个来源，在访问阶段，由受访者带来的误差。
假设前面的所有工作都做得不错，做得很好， 如果受访者拒绝访问，或者呢，没有能力作答，
作假、作弊、随意作答、回忆误差，也会造成随机误差、应答误差。
第六个来源，在数据清理阶段，由数据管理者带来的误差。
假设前面一切工作都做得很好，如果数据的管理者编制的数据录入程序有问题，
编码有问题，清理程序有问题，管理程序也有问题，
也就有可能会前功尽弃，既可能产生随机误差，也可能产生系统误差。
第七个来源，在数据分析阶段，由分析者带来的误差。
还是假设前面的工作都做得非常好，如果分析者分析工具选择不当，
模型建构不当，对数据有误读，也会造成研究误差。总之，任何一个环节
都有可能带来误差，前一个阶段带来的误差还会对后面的所有阶段产生消极的影响。
因此社会调查与研究的每一个阶段与环节， 都需要各类人员的密切合作与沟通，才能尽量减少误差。
在上述七个阶段中，涉及到调查活动的 有三个阶段，也就是设计阶段、抽样阶段和访问阶段，
这三个阶段涉及到的误差主要有第一，覆盖性误差与
抽样设计和抽样活动有关。第二，抽样性误差就是抽样活动造成的误差。
第三，应答性误差，指访问阶段产生的误差。第四呢，测量性误差，指测量、
测量工具产生的误差。这里，我们主要讨论与抽样 设计和抽样活动有关的两类误差，一类叫覆盖性误差，
主要指因抽样方制作不当带来的误差。
如果抽样方与研究总体不一致，就会产生误差，比如CGSS，
假定CGSS使用电话号码作为抽样框，就会出现覆盖性
误差，既会出现因为覆盖不足产生的误差，比如有些人没有电话，
就会被抽样方忽略，太穷的、太富的都有可能没有电话，或者呢，有电话，却不在电话簿的- 列表中。
也会出现覆盖过度产生的误差，比如很多人有多部电话，
这些人就有可能被过度代表，即使让抽样方正确地反映了研究总体，
抽样活动不可避免地也会带来误差，一个来源就是由抽样方法 带来的误差，比如，忽略样本特征而随意选择抽样方法。
还是我们的课题，入学机会的地区不平等研究， 假设我们对高中毕业生采用家户抽样方法，能抽到毕业生，
但是却比直接抽取高中毕业生的学校所产生的误差要大得多。
另一个来源是由变量特征带来的，其实，每一个变量 都有自己的抽样误差，当我们讲抽样误差的时候，到底指什么呢？
指的是主要变量的抽样误差， 例如，指主要变量的均值，用均值的标准误来代表误差。
当然，也有可能用相对误差来表示，比如说均值的变异系数， 就是相对误差的一种，至于均值的变异系数怎么算，
进入抽样专门课程，你们才会学得到，在这里，知道就行了。
除了抽样阶段的误差，访问阶段的误差也会涉及到抽样误差，尤其是应答性误差。
应答指的是受访者针对访题给出的回答，是社会调查与研究要搜集的数据。
如果受访者对整个访问无论是问卷，还是访谈，都不急于回答， 这就是样本无应答，又叫单人无应答，
指无法从样本得到任何应答，比如说受访人拒访， 或者根本联系不上，这一类的误差就是样本性的误差。
还有一类应答性的误差叫选项无应答，又叫访题无应答， 指受访者接受了访问，可能对某些访题不提供应答，
看起来这样的误差属于纯粹的访问误差，实际上不一定，也可以 被认为是抽样误差的一种，比如，某些访题涉及到稀有应答，
在抽样设计中，就需要予以考虑。
除了应答性误差以外，还有测量性误差， 由于与抽样误差关联不大，
我们只需要知道测量误差是由测量工具造成的误差，或者测量过程带来的误差就可以了。
对测量误差在讨论测量与测量工具的时候， 已经有过详细讨论了，这里就不重复。
总体上讲，在抽样阶段，甚至还要 考虑到访问阶段要通过抽样尽可能地降低误差。
四类误差的每一类都有降低误差的方法，
比如说抽样框，如果尽可能地把抽样框制备的准确一些，就能减少误差，
比如说抽样，如果尽量地让抽样过程规范一些，也能减少误差。
综合运用减少误差的方法，最后就能减少抽样阶段带来的误差，进而减少
调查总误差。抽样误差就讲到这里，谢谢大家。

---

## 误差计算

我们了解了误差的来源， 也在头脑中有了警醒，在抽样和访问中会努力减少误差来源和误差，
我们也知道了在社会调查与研究中，研究误差指的是具体变量，
由样本值推论到总体值时可能的差距，那么误差怎么计算呢？ 在讨论误差计算之前，我重复一遍，
所有误差来源产生的误差，最后都会反映在样本与总体之间的差距上。
问题是，什么样的差距呢？ 为此，在统计上专门有术语，统计量，用来表达这些差距，
包括偏差、均方误差，还有比如说样本均值，样本方差，样本标准物， 标准差，总体均值，总体方差
等等。注意，这些统计量指的是具体变量的统计量， 要比较的，也是具体变量的统计量。
还有不要忘记了，如果我们把抽样方法也当做是工具， 那么误差的来源只有两类，一类呢，是工具的误差，
一类是既有工具，也有人为因素的误差。
如果我们按照某一抽样方案反复抽样， 用样本估计值的数学期望，与待估参数进行比较，
它们之间的离差就可能是抽样方案造成的误差， 我们称之为偏差，bias，用离差表示。
还记得样本估计量？在抽样的逻辑中讲过，在用同一个抽样方案反复抽样中，
如果把每一次的偏差记下来，就构成了一个分布，样本估计量 的分布，这里算的不是样本分布，是统计量的分布，
就是偏差。
可是如果有各种方案，就会有多种估计值，其中还会有
人为因素的影响，这个时候，就既有偏差又有误差，我们统称之为误差， error，用均方误差来表示。
至于为什么要用离差，为什么要用均方误差，社会科学各学科的统计课程会告诉大家。
在误差中，由抽样活动导致的样本随机性 所造成的样本统计量与总体统计量之间的差异，被叫做
抽样误差。在抽样中呢，抽样误差是一个一般性的概念，包含着不同的统计量， 用于刻画变量变异性的分布。
如果误差不是由样本的随机性带来的，而是由其它的因素带来的，比如说 抽样框误差，测量误差，访问误差等等。
这些误差呢，被统称为非抽样误差。
对抽样而言，我们关注的重点是抽样误差。
我们知道统计量是用来刻画变量变异性分布的， 那么各种统计量的含义究竟指什么呢？
了解各种统计量的含义之前我们先介绍与统计量密切有关的两个概念，第一，参数值。
参数值，专门用来刻画总体某个变量变异性分布的状态，
比如总体均值，总体方差，总体比例，总体比率， 最常用到的是总体均值，总体方差
和总体比例。比例与比率还不一样。
比例，是指总量为一，p与q的之间的关系， 比率呢，又叫占比，指相对份额。第二，估计量。
估计量专门用来刻画样本某个变量变异性分布的状态，
通常也称统计量，统计值，估计量，在不同的场合有不同的说法。
常见的估计量比如说，样本均值，样本方差，样本比例。
这样，大家就要有一个概念，只要是讲参数值， 指的就是对总体的刻画，如果讲估计量呢，指的就是对样本的刻画。
在讨论中我们一再强调刻画的是 变量变异性的分布，那么在一般意义上如何概括变异性的分布呢？
最常见的刻画， 是对集中趋势和离散趋势的刻画，还记得在抽样的逻辑中，讨论收入
分布时候的情形？随着样本量的增加，样本估计量的平均值越来越
向总体平均值收敛，对了，刻画变量变异性集中趋势的
就是均值，分布越集中，同质性也就越强，反之，异质性也就越强。均值代表的是
要素的同质性程度或者异质性程度，这里给出的是总体均值的计算方法。
这个公式呢，应该容易理解，x拔代表均值，n代表总体要素数，
xi呢，代表一个具体的要素，把总体要素的变异值加总， 除以n，就是总体均值。
样本均值的计算方法一样。为了避免小样本条件下样本量对样本均值的影响，
在除法的分母部分，通常还要用样本量减去一，
可是仅仅知道了均值，并不能全面了解变量变异性分布的状态， 我们还需要了解其异质性，也就是离散趋势，
进而检验集中趋势是不是真实的，以及有多集中，这就需要用方差来刻画。
当知道了均值以后，每一个要素的变量值与均值之间都有一个关系值，
在样本中呢，观察值与平均值之间的差，又叫离差。
这个关系值，要么相等， 要么大于或者小于，如果用要素变量值减去变量均值，
可能得到的结果有三类，零，正数， 负数。如果把这些结果加总，关系值
的正负属性就会搅乱真正的关系属性。为了避免这个问题， 我们对每个关系值进行平方，就得到了每个要素与均值之间关系
值的平方，如果把这些关系值加总再除以总体要素n，
是不是就得到了一个要素值与均值之间差距的平方值？
这就是总体方差，表达要素在某个变量上与总体之间距离的程度，
当然方差越大，离散程度也就越大，方差越小呢，离散程度也就越小。同样，
我们也可以计算样本方差，把方差开方，就是每个要素与总体均值之间的距离，无论正负，
无论正负，同理呢，也用于样本， 当然在刻画样品估计量分布的时候，还有一些统计量，
比如说，四分位差，极值等等。不过知道均值、方差和标准差是最重要的。
对抽样而言，重要的是样本估计量方差， 又称之为估计量方差，统计量方差。在抽样的逻辑中，
我们提过，那么这个方差到底是什么意思呢？ 举一个例子，假设有一个总体，由三个人组成，他们的年龄分别是两岁，四岁和六岁，
现在假设从中有放回的随机抽取样本，
里边包含了两个个体，也就是样本容量等于二。假设一共抽了九次，
就得到了九组样本，这九组样本分别是二二，二四，
二六，四二，四四，四六，六二，六四和六六。
其实这是简化至极的例子，不太好。为什么呢？一般抽样不会这么抽，三个抽两个，
同时又是一个极好的例子，很容易告诉我们方差从哪里来。
如果我们按照实践来， 譬如假设有一百八十个人抽三十个人，实践上是相符了，但是
对于方差的说明却复杂了。我们用这个例子是希望让大家知道方差从哪里来， 就好了。我们用图表来看，这边是样本，
我一共抽了九组，这边呢，是样本均值，大家看均值的差异有多大，
这是呢总体均值。是四，如果选两个四组样本，
看看估计量方差，假设第一个选这四组，
那么它们的方差就是0.6667，如果选这四组呢？
这一组的方差就是2.6667，这里大家就知道内部
的差异有多大了。用这个例子我们希望说明，均值与方差， 对理解内部差异性，异质性，是非常重要的估计量。
误差计算，还涉及到其它估计量， 对初学者而言呢，理解均值、方差、标准差也就足够了。
误差计算就讲到这里，谢谢大家。

---

## 必要样本数

从简单随机抽样开始，同学们可能一直都憋着一个问题： 老师不管采用哪种抽样方法，在哪一层抽样，在哪个阶段抽样，
到底要抽多少样本合适啊？ 坦率地说在我的教学生涯中这个问题是在讨论抽样设计和抽样方法的时候，
被问到的最多的一个问题，当然也不是可以简单回答的问题。
对初学者而言， 大家做类似于CFPS，CGSS这样一类大型的调查抽样设计
机会不多，是因为这一类的调查要花很多的钱。
委托方投资方要把这笔钱给你，心里可能不太放心。作为初学者
开始接触大多数是比较简单的抽样，即使如此 我们还是要理解无论是大型调查还是小规模总体的抽样，
样本量始终是一个问题。还记得我们在讨论简单随机抽样时关于收入的估计？
样本量的大小直接影响到估计误差对吗？ 那么是不是样本量越大误差就越小呢？不一定。
我们考虑了异质性同样还要考虑同质性，还要考虑我们有多少资源。
因此与样本量相关的因素就非常重要。
对与样本量的大小确定除了要素在研究变量上的异质性以外，
主要受到以下因素的影响。第一个因素是对估计精度的要求， 以及估计精度的影响因素。
对估计精度的要求来自两方面。
一是所采用的分析方法，一是对总体推论的误差。
假设所有的操作都没有问题，误差的主要来源就是缺失值。
比如说我做淘宝店主研究时候，发了六万份问卷， 只回收到了2%的应答，这事儿听起来就不大靠谱，
可幸运的是淘宝店主是一类同质性很高的总体，
如果抑制性稍高一些调查也就失败了。第二个影响因素呢是总体规模的大小。
通常小规模总体样本量的大小对估计误差的 影响比较大，会倾向于让样本量要大一些，
大规模的总体呐，样本量的大小对估计误差的影响不大， 通常会运用多种方法尽量采用合理的样本量。
第三个影响因素是应答率，应答率的多少直接影响到 获得数据样本的多少，进而影响到测量效率，
应答率高通常就会采用合理的样本量，应达率低呐通常要增大样本量。
第四个因素还有可用资源的多少。
可用资源多为了保守起见，通常会对样本量做保守估计， 既尽可能增大样本量，反之亦然。
在这些条件约束下到底抽多少样本才能使得代表性又好又经济呢？
我们先依据简单的随机抽样来看，假设估计值为总体均值，
且可接受的误差水平为α，那么均值的
置信区间就是这样的，在这个公式里， X为总体均值，这一值是标准的正态分布值，
也是置信度的临界值，又叫可靠性系数，可以查正态分布表。
之所以用二分之α，是假设误差为双边分布，既可能是正向分布也可能是负向分布。
σ为总体标准物，n为样本量， 用可接受的误差水平的标准正态分布
乘以后面除得的结果就是可接受的误差值， 也就是抽样误差，在这样的条件下简单随机抽样的样本量就是这样的。
其中我们知道分子有两个数，一个呢是可接受的误差水平的
双边Z值的平方，一个呢是总体均值的方差就又叫总体均方差， 分母呢就是抽样误差的平方，
如果不是总体均值而是总体比例，那么抽样误差就是这样的。
样本量呢就是这样的。我强调一遍SRS是最差的抽样方法，
底线的方法，当然也是最简单的抽样方法，也是其他
抽样方法计算样本量的基础。在遇到复杂抽样的时候比如说多阶段抽样，多层抽样
通常会在简单随机抽样的基础上还要考虑设计效率的影响。
样本量就等于设计效应乘上 简单随机抽样条件下的样本量，记住这个就行了，待会儿再讲设计效应。
如果是愈抽样本还要进一步考率应达率的影响。欲抽的样本量等于理论上要抽的样本量除上- 应答率，
抽到的样本量比理论样本量要大，
又叫扩大抽样。到底抽多少样本是一个既经济又准确的抽样呢？
从前面的讨论中我们了解到总体方差，允许误差，可靠性系数都会影响到对样本量的要求，
总体方差越大需要的样本量就越大，反之亦然。允许误差越小，
需要的样本量就越大，反之亦然。可靠性系数越大， 需要的样本量也会越大，反之也亦然。
这样到底抽多少样本量就不是一个简单的科学问题了， 还取决于研究变量与研究对象之间的关系。
对大规模的社会调查与研究而言， 研究变量不是一个而是很多个，如果同质性强，样本量小也可以，
举个例子，在做谁在开网店的研究时， 我只用了2%的应答样本，所以我这里讲的是应答样本。
除了应答样本以外，我还从两百万个合约店家中抽取了六万个店家，
如果仅仅是2%的应答样本对估计而言我是没有把握的，但是有了六万个店家的数据呢，
估计起来就有信心了。如果内部的异质性很大，
那就需要做复杂的考量了。对于小规模的研究而言一般经验上样本量最小的为三十个，
统计上如果n大于三十就被称之为大样本了。
影响样本量需求大小的还有一个因素就是抽样效率， 在等误差要求的条件下，抽样效率越高，
样本量需求就越小，反之如果抽样效率越低呢， 样本量的需求也就越大。
那么什么是抽样效率呢？抽奖效率指
指在等样本量条件下两种抽样方案的抽样方差之比。
假设有a抽样方案和b抽样方案， 如果a方案比b方案的估计量方差大，
那么就认为b方案的抽样效率高。抽样效率的评价是比较得来的，
不过如果估计量是有偏估计就会遇到问题， 这个时候还要考虑到偏差因素，
不能用估计量方差来比较而需要用均方误来比较。
在复杂抽样中与样本量有关的还有设计效应因素。
在讲复杂抽样样本量时候已经讲到了这个概念。
设计效应指的是某种抽样设计估计量方差与等量样本无回访 简单随机抽样方差的比值，
分子是某种抽样方案的估计量方差，分母就是简单随机抽样估计量的方差，
经验上设计效应在二左右就已经是很好的方案了。粗暴的说，如果是二，
表示用现在的抽样方案抽两个样本等于运用简单随机抽样方案抽一个样本，
有同学说那是不是还不如简单随机抽样呢？可问题是简单随机抽样方案
在复杂条件下根本就没有办法应用，到底哪个好哪个差？ 更何况这里还没有将抽样效率纳入考量。
这一节的内容相当的丰富，同学们需要花一定的时间来消化， 建议同学们给自己一些耐心，我们做一个小结。
第一使用等概率原理的概率抽样一般有多种方法， 其中简单随机抽样方法是基础，同时也是底线。
在这个基础上还有系统抽样，整群抽样， 这些都是一次性抽样或者末端抽样所使用的方法。
如果是复杂抽样通常要使用与规模成比例的概率抽样方法 或者分层抽样方法或者多阶段的混合抽样方法，
这些方法通常都是在末端抽样之前的方法。
多阶段抽样通常混合了不同类型的概率抽样方法， 抽样无论是抽象设计还是抽样过程
都是用样本估计总体使得误差来源之一， 尽量的降低由抽样带来的误差，
需要在可用资源与期待结果之间进行策略性的安排需要创造性。
不管怎么抽，样本量是抽样的一个重要考量， 影响样本量的因素主要是总体的异质性程度，
可接受的误差和可靠性系数，抽样效率，设计效应 还有应答率。
如果有同学确实对样本量问题有兴趣可以参考由科学出版社出版的，耿修林的著作
《社会调查中样本容量的确定》。
概率抽样这一节就讲到这里，谢谢大家。

---

## 抽样方案

有很好的抽样活动，也选择了合适的抽样方法，
通常做抽样设计的人不一定就是执行抽样的人。即使是，为了保证抽样过程的严谨，
也需要一个文本，用来指导抽样活动，这就是抽样方案。
如果说抽样的逻辑，概率抽样、非概率抽样是理论问题，
尽管在讨论中呢，我们运用了例子，不过呢，还是就方法本身在讨论， 而不是就研究问题的操作在讨论。
抽样方案则涉及到具体操作了，是一个设计文本， 是以研究问题为牵引的研究设计的一部分。
要说明的是，采用什么方法，采用哪些步骤， 获得用于收集数据的样本。对于综合性的研究而言，
抽样方案就是收集数据设计非常重要的一部分。
在CFPS的设计中，从2006年到2010年， 我花了五年的时间和我的团队一起做抽样设计、调查设计，
也花了不少钱。
不要说大型抽样，只要做研究， 涉及到用概率方法收集数据，就一定要有抽样方案。
无论简繁，都要对抽样的要素，比如总体，研究总体，
抽样框，抽样策略，抽样方法，抽样的实施等做出具体的说明。
按照研究项目的管理逻辑，在研究项目的申报中，在涉及抽样的研究计划书中，
抽样方案是必须的一部分，而且是非常重要的一部分。
在抽样方案中，抽样方法的选择是核心内容。
一般情况下，抽样方法的取舍取决于三个基本因素， 要素的同质性，总体的规模，还有变量的多少。
我根据自己的经验做了一个概括，供大家参考。至少是大家选择抽样方法的一个线索。
第一，如果总体规模很大，异质性很强， 研究变量很多，通常会采用多阶段、分层的PPS抽样。
第二，如果总体规模很大，异质性也很强，研究变量很少，
通常采用多阶段抽样，末端通常采用整群抽样或者配额抽样。
第三，如果总体规模也很大，同质性也很强，这个时候，变量的多少没有太大关系，
通常会采用多种抽样方法，比如说末端采用就近抽样、判别抽样，
也可以采用概率抽样，不过呢，一般的情况下会采用非概率抽样。
第四，如果总体规模很小，异质性很强，
变量多少都没关系，通常会采用滚雪球、RDS抽样或者是知情人抽样。
由此看来，最重要的有两个因素，总体的异质性和总体的规模。
作为文本，一份对研究具有支持意义的研究方案，需要让评审者清晰的判断抽样的科学性、
可行性、可操作性，需要让从事抽样的人呢感受到方案的可操作性，
按照方案进行抽样。为达到这样的目的，一份抽样方案 在内容上至少要有以下的内容，第一，总体。
不仅要把总体界定清楚，还要明确地界定研究总体、框总体，或者叫抽样总体。
如果采用多阶段抽样、分层抽样的，还要说明每一个阶段、每一层的抽样框。
第二，研究对象。包括调查对象或者研究对象， 就是收集数据的对象，受访者。比如说CGSS
调查对象是家庭中的个人，CFPS调查对象呢就是家庭中的所有成员。
第三，样本量，尤其是末端抽样单位的数量要做明确的说明。
第四，抽样方法，如果采用复杂设计，例如多阶段混合抽样，那么每一个阶段的抽样方法都要- 做说明。
第五，如果采用多阶段混合抽样，或者多阶段抽样，每一个阶段的抽样单位、抽样框、抽- 样方法、
样本量的配置以及末端抽样的方法也都需要写清楚。否则呢，读者就无法知道每一个阶段- 的权重。
第七，如果不是采用大量熟悉的抽样框，自己在制备抽样框，还需要说明
抽样框的制备方法。大型调查中的抽样框制备 也是一项复杂的工程。第八，还包括估计量的计算方法。
比如说，权重到底怎么算，怎么配权重， 如果是多阶段抽样，等概率又怎么保证。我们举两个例子吧，
两个大型调查的例子。大家已经很熟悉了，我们把两个调查的抽样方案的目录都找过来了。
第一个例子是CFPS抽样方案的目录。我们可以看第一，调查对象与
目标样本量，说明调查对象是谁以及抽多少样本。
第二，抽样设计总原则，介绍分层、分阶段抽样的理由与原则。
第三，各阶段的抽样，分第一阶段抽样、第二阶段抽样、第三阶段抽样，依次到末端抽样。
第四呢，还有一个再抽样。CFPS有六个总抽样框、
五个大省各自一个抽样框，二十个小省 是一个抽样框。当把五个大省与其他二十个小省样本结合在一起
在国家层面作推论时，就需要对五个大省的样本再次抽样。
不然，五个大省的样本与二十个小省的样本量比例就不对， 不是等概率的，需要通过再次抽样，
让二十五个省市自治区作为一个总体的备选概率相等。
第五，说明权数。接下来一共还有五个附录，
说明具体的技术性细节。这一份抽样方案虽然只有十七页，却交代了每一个阶段到底怎么操作，
并证明所有操作作为一个整体如何满足了等概率原则。
我们再看看CGSS的抽样方案，虽然写法上有一些不同， 但主要内容是一样的。第一，调查背景，交代调查的重要性和必要性。
第二，调查的目标总体。第三，抽样设计的原则。第四，抽样设计中的
几个问题，涉及到分层、各阶段的抽样单位、样本量的确定与分配。
第五，具体设计，介绍了分层的方法、各层抽样的方法。第六呢，
最终的样本构成。第七，样本权重的确定。第八，估计量的计算。
第九，方差的计算以及附录，
把PSU都列出来了。对总体的说明，对研究对象的说明， 对样本量的说明，对抽样方法的说明，对多阶段的说明，对抽样框制备的说明，都在这，
一个都不少。对于初学者来讲，尽管不需要做的这么复杂，却也需要清除明白。
为此呢，我给大家一些提示。
你们要知道，做抽样方案的人，总希望有一套完美的方案。
我做抽样方案的时候，甚至希望把每一个异质性因素都纳入考量。
不过，任何抽样方案都会受到资源有限的约束，也会受到可及性不足的约束。
因此最终的抽样方案，总是在资源、可及性与完美性之间的一个取舍，
是一个妥协。可以有理论上比较完美的设计方案，却常常不具备操作性。
任何可以操作的方案呢，却总是有瑕疵的方案。这样，抽样方案只能尽力，
尽量做到把研究对象界定清楚，把抽样每一个环节的对象与边界界定清楚，
比如说CFPS的家庭户，CGSS的个人。
尽量地界定总体、研究总体、抽样框。
避免造成覆盖性误差。说到底，抽样其实是一个遗憾的因素，
最后总要做取舍。做完取舍就会遗憾，这个没有想到，那个没有想到。之所以要做抽样方案，- 就是希望通过文本的
形式，梳理抽样的各个环节，尽量使得没有想到的事少一点，影响小一点。
下边，对这一节的内容做一个小结。
抽样方案是抽样工作必备的文件。
抽样方案的内容需要对涉及抽样 各个环节及其工作做出说明。
这一节的内容就到这里。

---

## 抽样实施

即使有很好的抽样方案，如果不落到实处还是没有样本。
抽样的实施一般来讲，根据抽样方案按照研究设计做就行了。
听起来很简单，不过千万别大意。
获得样本真的是一个非常艰难的过程。举一个例子，制备CFPS抽样框的时候，
我们做过多次测试。其中有一次，我们到西局， 北京西站附近的一个社区，那儿离北京市长途汽车站非常近，租房子的人呢比较多。
走近一个大院只有一个门儿，
看起来是一户人家。可是进门以后却发现，两边各有八间房都是出租的。
怎么办？到底算一家人还是算17家人？
在抽样实施中，有时候不是那么简单，不是简单地按照方案做就行了。
方案永远都是一个未定的方案，不可能把所有的复杂性和变异性都纳入考量。
尽管如此，方案还是抽样实施的指南，抽样实施就是按照 抽样方案或者抽样实施方案
获得样本的过程。不管是简单抽样还是复杂抽样，一次抽样还是多次
抽样，没有落到地上的抽样，没有实施的抽样都只是纸上谈兵。
再说刚才的例子，我们设计的很好，按门来，一门一户，可是遇到西局的情况就得具体处理。
在实践中还有更复杂的。大家知道在北京市西城区的辅方桥， 大部分都是四合院儿。我们就遇到一个情况，初看的确也是一个四合院儿，
跟别的四合院儿不一样的地方就在于它 是一个两层楼的四合院儿。在第二层上有一个门儿，
打开门就是一个楼梯，走下楼梯后面还有 一个院子。这个院子呢也只有这一个进出口，没有别的进出口。
不打开这扇门，后面的院子就漏掉了。
因此抽样设计，抽样方案，实施方案一定要落到地上。
从例子中我们看到，实施也是控制误差的重要环节。
为了便于操作我根据自己的经验， 概括了抽样实施的五个步骤供大家参考：
第一，正确地理解方案，制定每一个环节的实施方案。
抽样方案只是指引，指南，索引，在实践中在操作中还需要
实施方案。第二呢？组织资源。比如人力，社会关系，设备，后勤保障等等。
稍稍大一点的调查就得请人，请学生，请朋友，怎么计酬，怎么支付这就是后勤问题。
后勤对社会调查与研究也非常重要。
第三，培训抽样人员，督导人员，后勤人员。把实施中可能遇到的问题讲透彻，
把合作与分工讲透彻，让每一个人明确的知道自己到底要干什么。
第四，逐步实施。一般来讲，前三步工作做完以后就一步一步地实施，
先从制作抽样框开始，再抽样， 最后再做质量检验和误差估计。
举一个例子，末端抽样框的例子，CFPS的例子。
我在组织CFPS的时候根据中国国情做了一套末端抽样方法， 《地图地址抽样框制备手册》。
这是我们综合了已有的末端抽样框制作方法创造的一个方法。
比如说，我们根据测试阶段遇到的情况，列出了在制做末端
抽样框的时候，如果遇到了一宅多户和一户多宅怎么处理？ 边界怎么界定？
无法确定是否是住宅时怎么处理？以及大社区如何拆分等等。
在抽样实施中，每一个抽样都有自己的特异性， 不过呢？也有一些常见的错误提出来希望大家能够避免。
第一类错误，理解类的错误。
对设计理解不太准确。比如说，CFPS的家户，到底什么是
家户？CFPS对家户有很严格的定义，一般情况下，操作人员认真看定义可能还会有不明白- 的地方。
如果按照不明白的理解去做，就会带来误差。
更严重的是根本不看定义，按照自己的日常生活中的理解， 就一定会带来误差。
为了避免误差操作人员一定要认真阅读操作说明，不明白的一定要问，问明白问清楚再操作。
第二类，操作类的误差。如果理解上没有问题，操作中的误差常常有两类。第一，
马虎。比如，遗漏了一宅多户中的户；一户多人中的人。
第二，作弊。比如由于执行的困难，故意作弊或者臆想。
调查点如果很远不想去，就自己随意的想象了。
在制作CFPS末端抽样框的阶段，我在甘肃省核查的时候去了一个村子。
这个村子明明有73户人家，结果 绘图员在图上只标明了56户。
我问还有十多户上哪去了？
我到村子里拿着图一步一步地看，发现绘图员把距村子大概有半米路远的一个小聚居给弄丢了，
正好是十多户，这就叫作弊。因为执行的困难而作弊。
当然还有一些经验也可以与大家分享。在 抽样的实施中，多问自己几个问题。第一，总体到底有多大？
到底多大范围的调查？ 第二，研究总体在哪里？有哪些会影响到对调查对象的识别？
第三，有没有可用的抽样框？比如说，有没有可能让执行人提供一个抽样框？ 如果没有怎么制备抽样框？
第四，选择什么样的抽样方法可以减少误差？第五，执行的难点
到底是什么？怎么样去组织资源能够使得我花最少的钱最有效地办事儿？
其中最重要的一条经验就是多沟通。
与相关各方尽可能就抽样设计， 抽样实施的目标达成一致。这就是经验之谈。
不要怕多事儿，尽量地沟通，有错误有误差说在明处， 总比最后再实施以后做辨解要来得容易的多。
下面对这一节的内容做一个小结：
抽样的实施，在实践中是科学与管理的结合。既要理解抽样设计的每一个环节，
又要依照设计，在每一个环节有效地执行。
因此，就抽样实施而言，不仅对智商提出了要求，也对情商提出了要求。同样呢，
抽样实施也是各方妥协的过程。对于减少抽样误差减少设计误差非常
重要。沟通是解决各种问题的根本之道。这节的内容就到这里。
下边我们对这周的内容做一个归纳：
这一周的内容非常多，相信同学们一定疲惫了。不过呢我们还是要做一个小结。
我们不做繁复地概括了，在更抽象的层次上把不同内容之间的逻辑串联一下。
总体要素的同质性和异质性，为抽样提供了基本的条件；
抽样估计的经济性，为抽样提供了充分的理由。
用样本估计总体的基本原理来自于等概率原理；
最重要的原则，就是尽量减少误差。抽样策略，抽样方法的运用都需要在经济性 和减少误差之间达成平衡。
如果变异性满足随机性原则，就可以运用概率抽样方法，
每一种方法的应用情景，要根据总体规模， 异质性的程度，变量的多寡而定，在大规模抽样中，灵活运用多种方法，是减少成本
减少抽样误差的有效方法。
如果变异性不满足随机性原则， 就可以运用非概率抽样方法。对一些稀有的研究对象，
可以采用特殊的抽样方法，但还是要注意的是，非概率 抽样中，某些阶段也可以运用等概率原理。
任何抽样一定要有一份抽样方案的文本。
不仅通过对抽样设计的完善来降低成本减少误差， 也为抽样实施提供指南。
抽样实施，既需要充分理解设计意图，也需要结合实际情况
灵活处理。选这类研究实践的同学这周的课程结束以后，就要把自己的研究题目
假设要通过抽样来搜集数据进行处理， 选择抽样策略，选择抽样方法，并且纂写抽样方案。
这一周的内容就到这里， 谢谢大家！

---
layout: false
class: inverse, center, middle, duke-softblue

# 2.3 数据整理

---
layout: true
  
<div class="my-header"></div>

<div class="my-footer"><span>huhuaping@   第02章 数据收集、整理和清洗   
&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;
&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;
2.2 数据整理</span></div> 


---

## 数据整理的工作流程

在数据收集过程中，重要的是条分缕析。让数据的相关信息清清楚楚，用起来方便，不至于混乱。 

- 分类存储

    - 依据数据的载体类型、研究的时间需来进行分类，并且把分类好的数据，无论是什么载体形式的数据，采用合适的存放工具进行存放。  
    - 比如，纸板问卷，不能随便堆放，需要按照一定的分类标准进行存放，便于后续的工作。比如，录入，质量评估，复查等等。  

- 建立目录

    - 存放的目的不仅仅只为了存储，更重要的是为了便于使用，建立目录就是便于利用的方式之一。 
    - 目录是用于检索的，对调查获得数据建立目录，也是为了方便检索。  

- 编制索引

    - 对于复杂数据，还需要在目录与存储之间建立关联，这就是索引

---

## 收集整理的工作记录

数据收集和整理中不仅需要核实，还需要记录，做笔记，把搜集数据、整理的工作信息记录整理清楚。主要记录：

--

.pull-left[

- 数据来源信息：

    - 如调查项目，调查人， 采集人，采集时间，地点，对象。

- 数据载体类型信息：

    - 具体是什么载体？ 比如，纸张的、数字的。  

- 数据描述信息：关于数据基本状态的描述

    - 有多大规模，什么内容，关联什么主题，等等。 

]

--
    
.pull-right[

- 数据分类信息：

    - 无论是按照载体形态分类还是按照其他标准分类，一个大型项目需要对原始数据根据数据使用，建立基本分类。  
    
- 数据存储信息：

    - 数据以什么样的载体，什么样的方式存储在什么位置？ 
    - 与数据安全相关的信息，如存储的版本、份数、时间变化关系等。  
]

---

## 数据化检索和数据安全


>“老师，能把上星期发给我的课件再发一遍吗？我忘记放到哪了？”

>“老师，非常的崩溃！电脑的硬盘坏了，写的东西都没有了！”

上述记录信息要尽可能的保存若干个版本。

- 纸和笔的传统版本。便于在需要的时候翻阅，尤其是使用范围相对较广的数据。 

- 数字化可检索的版本。为什么要做数字化的可检索版本？

    - **目录树法**（相对简单的数据）
    
    - 建立专门的**数据库**（针对异常复杂或庞大的数据）


---

## 数据化检索和数据安全

数字化数据有一些需要特别注意的问题：

--

- 数据存储。随时都有若干个备份！

--
    - 数字化的数据从最初的纸袋到今天的磁盘、硬盘，有各种介质。由于介质的可靠性不同，数据的安全性也不相同。
    - 美国的“911”事件。美国联储会的主席格林斯潘知道这个消息的第一时间，他担心的  不是“911”的伤亡情况，而是美国金融数据的安全。

--

- 数据安全。安全的风险，要么来自于使用者的误操作，要么来自于内部或者外部的有意攻击。

--

    - 离线保存的目的不仅仅是为了应对各种预想不到的不测，更重要的是为了防止数据泄露。
    - **斯诺登事件**：任何在线数据事实上都是不安全的，都有安全隐患。

---

## 数据化检索和数据安全

**文本数据**的安全：

- 文本数据的安全威胁主要来自于不可抗力的一些因素，比如说自然灾害、风蚀等。

- 当然也来源于人为因素。比如说错误的识别，本来是很重要的数据，却被当作了废纸。


**非数字化数据**的安全：

- 图片数据的载体形态比较复杂，胶片、图片由于介质存储特征的差异，不可以混合放置而保管。如胶片就需要防潮，通常要使用防潮器皿。 

- 实物数据的安全具有独特性，应根据实物实物特征进行科学整理和安全管理。比如说兵马俑，那就在兵马俑的原址上盖一个博物馆进行整理。


---
layout: false
class: inverse, center, middle, duke-softblue

# 2.4 数据清洗

---
layout: true
  
<div class="my-header"></div>

<div class="my-footer"><span>huhuaping@   第02章 数据收集、整理和清洗   
&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;
&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;
2.4 数据清洗</span></div> 

---

## 数据清洗工作的内容

**数据整理**主要是分类和梳理，**数据清洗**主要讨论的则是检错。通过这两部分的工作减少人为的误差，降低调查误差。数据清洗包括四个工作内容：

- **真实性评估**：确认数据是真实的，不是道听途说，不是张冠李戴，更不是杜撰臆想。
    
    - “假新闻”现象就是调查数据在真实性层面出现的问题。
    - 微信群里“令人发指”的各类长辈转发

- **完整性评估**：数据应与研究工作的目标要求相符，研究不需要的就不应该出现在数据中，研究需要的在数据中就不应该缺少。 

    - 如果需要补值，就应继续补充收集数据。

---

## 数据清洗工作的内容

- **可用性评估**：数据是不是可以用于数据库化了？如果不能，还需要做怎样的数据加工？

    - 比如对图片数据、 音频、视频数据，甚至文本数据是不是还要做数字化工作。
    - 对于**痕迹数据**，尤其是大数据，如果不是直接采用大数据分析，而是应用于单机分析或服务器分析，是不是还要根据数据量进行抽样。
    - **脱敏化**处理。对有可能泄露受访者隐私、泄露传感器使用者隐私的部分，还需要做匿名化工作。 

- **错误性评估**：评估数据可能的错误来源、可能的错误大小，及其对数据质量的影响。 

---

## 数据清洗工作的内容

以**调查问卷数据**的清洗为例：

- 真实性的清洗：要确认数据来自于受访者。 

- 完整性的清洗：主要看样本无应答，也就是一整份问卷没有应答。以及选项无应答，也就是应该应答的访题没有应答。 

- 可用性的清洗：主要是看编码是否完成，权数是否可行，以及缺失值如何标记和处理。

- 错误性的清洗：主要是清洗调查环节的错误，比如样本错误、应答人错误、应答方式错误。


---

## 数据清洗工作的记录

清洗数据工作中的每一项活动都要有记录。记录信息包括：

- 清洗工作的信息记录： 

    -数据清洗每一个步骤的做法、参与人、时间、地点、过程信息。 

- 与清洗内容相关联的信息记录：

    - 数据真实性信息。比如是否真实？是否存在编造、作弊嫌疑？哪些部分存在不真实？ 怎么样不真实？等等。
    - 数据完整性信息。比如是否完整？是否有缺失？如果有缺失，哪些部分缺失？缺失哪些数据？等等。
    - 数据可用性信息。比如问卷数据是否加权？录音数据是否转录为文字？痕迹数据是否数据化了？大数据如何处理？是运用云计算策略，还是裁剪为单机计算容量？等等。
    - 数据错误性信息。比如问卷数据中的缺失，文献数据中的差错，以及其他可能导致误差的差错等等。 


---

## 数据清洗记录的备份与安全

数据清洗的记录信息应尽可能地保留若干不同的版本。一般包括纸笔版本和数字化版本。纸笔版本便于随时翻阅，数字化版本，便于交流，也便于检索。 

- **笔记的清洗**。不管是哪一类的笔记，所有的笔记都有私用和公用之别，通常人们做笔记都是做给自己看的（**私用笔记**）。

    - 你把自己的笔记给别人看，别人能看懂吗？
    - 在正式使用之前，需要把笔记数据通过清洗，变成任何使用者都可读的笔记（**公用笔记**），
    - 这就是格式化问题，就是把你个人的笔记清洗为数据笔记。 

---

## 数据清洗记录的备份与安全
 
- **对音频要抄录**：

    - 把语音文档，不管是磁带录音，还是数字录音，抄录为文字，表述为文字或者文字加图片这样的格式。
    - 数字录音还有一个**格式清洗**问题，不同数字设备的录音，可能会 采用不同的格式。
    - 比如olympus的早期设备，采用的就是它自己的格式，DSS格式；如果不是采用它自己的软件就读不出来，最好呢，是转化为通用的格式，比如mp3格式。 
 
- **对视频清洗编码**：
    - 如果是非数字录像，最好先转化为数字格式
    - 如果已经是数字录像，对视频清洗编码需要给出**时间记录码**。

---

## 数据清洗工作的几点忠告

> 哦，已经数字化了，可以扔了，那个没用了，可以扔了。

- 不要轻易地丢弃任何一段看起来没有用处的信息，信息载体。

- 清洗不是仍东西，是清洗数据，让数据清晰化。

- 清洗的目的就是将特异性的数据，转化为公共性的数据、分析研究者都可以读的数据。

- 在清洗的过程中，千万要保留原始观察记录。

    - 一般而言，原始问卷至少要保留十年以上，访谈记录和观察笔记一般要求永久保留。

---

## 数据清洗例举1：观测性数据


以**观察性研究**中数据的清洗为例：

- 观察性数据有一个特点就是差异性，对同一个场景、同一个事件，不同的人去观察，看到的并非完全一致。 

- 每个人的观察记录，都有自己的习惯，有的习惯于采用速写和密写，比如说有些人为了防止别人看他的笔记，长采用密写的方式。 即使是结构式的观察，不同的观察者也会有特异性。 

- 观察性数据的清洗就需要把各类个性化的个人观察数据转变为标准化的观察记录。

---

## 数据清洗例举2：文献数据

以**文献数据**的清洗为例：

- 笔记的清洗。 比如说：研究用的素材如文献的阅读、标注与笔记、摘录，如果希望未来继续使用，那就需要**格式化清洗**，把素材转化为数据。如果有必要，还可以为下一步的数据库化做准备，比如编码。 

- 文献的清洗。对阅读过的文献，如果已经获得了数字版本，就需要与数字版本关联的编目信息、阅读信息关联起来整理，结合后边讨论的数据库化工作，把它们转化为个人档案馆。如果没有数字化的版本， 则需要将文献信息与阅读笔记信息关联，结合后边讨论的数据库化工作，把它们变成个人的档案阅读目录数据馆。 


---

## 数据清洗例举3：痕迹数据

以**痕迹数据**的清洗为例：

对痕迹数据的“四性”评估和清洗，一般是直接依据数据的来源来确认的。

比如，来自于**网络爬取**的数据，和来自于**数据拥有者机构**提供的数据，其它的**平行数据**等等。

一般而言，如果数据来源的渠道没有问题，数据的四性就不会有太大的问题。 

清洗痕迹数据最重要的一项工作，就是把**非格式化数据** 清洗为**格式化数据**（Why？至少目前的分析工具还不支持直接分析非格式化的数据）
 

那么格式化与结构化有什么区别呢？

**数据格式化**：把混杂在一堆数据中的各类数据清洗出来，分门别类。比如说日志数据中的用户行为数据，以淘宝数据为例，订单数据、发单数据、物流数据等等，分门别类整理出来。 

**数据结构化**：把各类数据和变量进行多维度关联。比如把以上日志数据中的各个子集关联到用户之下，形成类似于问卷调查数据的每个**样本数据**。 

---

## 数据清洗例举4：大数据

如果**痕迹数据**是**大数据**，情况就有些不同了。

在清洗数据之前，需要把**清洗策略**测试一遍，然后就可以直接采用大数据的清洗模式了。

- 从大数据中抽取数据，或者是从网页上爬取数据，在处理中尽管不一定会用到云计算， 在处理逻辑上还是一致的。 

- 大数据的清洗，目前运用比较普遍的是Hadoop框架下的Map Reduce。

---

## 数据清洗例举4：大数据（以阿里巴巴案例）


>阿里巴巴有淘宝、天猫、一淘等等业务，这些业务每时每刻都在产生数据，这些数据涉及到信用、金融、物流、管理等等业务操作。
所有这些操作的数据都会汇集到数据交换平台，由此构成了阿里巴巴的数据动态。

>2014年的双十一期间，6个小时之内的处理量就已经达到了100个PB。在产生的这些数据中，既有结构化的数据，也有非结构化的数据，进出数据平台的数据不是个，不是匹，而是流。这些数据流，通过数据处理就变成了中间层的数据，可以运用和应用于服务，中间服务，既可以对内，又可以对外。 

---

## 数据清洗例举4：大数据（以阿里巴巴案例）

问题是，这些数据是怎么处理的呢？数据清洗关心的正是[这个问题](https://www.alibabacloud.com/help/zh/doc-detail/27875.htm)。

```{r}
include_graphics("pic/chpt02-alibaba-map-reduce.jpg",dpi = 80)
```


???

我们来看看同学们初次听到这个概念可能会有些晕，没关系，我们这样理解， Hadoop相当于云计算，或者是分布式并行计算的操作系统，类似于个人电脑的Windows，或者是OS X。

这个操作系统下，有自己的文件系统，类似于Windows上有资源管理器，OS X下有Finder。也有它自己的数据库，比如，Hbase，类似于Windows上的数据库，比如微软的Access。 

不过呢，不管是文件系统还是数据库，与个人电脑最大的不同就在于它不是在一台电脑上，而是在成百上千台电脑上组成的分布式网络上，就像是一个军团。 对我们的数据清洗而言，实时记录的存储的大数据，通过这个框架系统，可以为清洗提供计算接口。其中，Map Reduce就是清洗数据的一个应用。

第一步，map，分布式的分类， 

第二步，reduce，就是分布式的合并同类项。

经过这两个 步骤，原来混杂的非结构化、结构化的数据变得结构化了。 其实呢，在map和reduce之间还有一个步骤，叫shuffling， 

就是通过交换位置的方式归类。我们来看例子，数据平台的 数据流，是什么数据都有的，这幅图呢，从左到右， 平台的数据就是Map Reduce的输入。 

第一步，通过分布式系统在云里分派任务， 

第二步，mapping，就是分类， 

第三步呢，通过交换位置进行归类，

第四步呢，reducing，就是把已经归类好的合并同类项，由此获得的产出是格式化的、结构化的数据， 可以用于分析与研究的数据库化的数据了。 这就是大数据的清洗，这些步骤都是在系统中完成的。 

---
layout: false
class: inverse, center, middle, duke-softblue

# 2.5 数据的数据库化

---
layout: true
  
<div class="my-header"></div>

<div class="my-footer"><span>huhuaping@   第02章 数据收集、整理和清洗   
&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;
&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;
2.5 数据的数据库化</span></div> 

---

## 为什么需要把数据进行数据库化？


> 数据不仅整理好了，也清理好了，是不是就可以分析研究了呢？

- 采用手工计算的情形几乎已经消失了。数据的数量与复杂程度，已经超出了人们运用大脑、纸和笔，直接处理的程度。

- 调查数据的分析与研究，从计算机应用普及以来，就已经主要依靠计算机了。运用计算机是最有效和最快捷的方式。 

- 运用计算机就需要满足计算机对数据的要求，那就是**数据库**。 

    - 清理整理好的数据，要变成计算机可以读取并进行运算的数据格式，通常这一类的格式都是数据库格式。
    - 计算机应用程序不同对数据库的格式要求也不相同。

数据库化的目的就是为了便于分析和使用。不同数据的数据库化，有不同的方式跟方法，基本的要求是通过数据库化，让调查数据格式化、结构化，符合统计分析、计算对数据的要求。

---

## 数据库化的类型

**数据的数据库化**，就是把得到的变量、变量属性或者标签输入计算机，变成结构化的**数据矩阵**。从数据库化的目标来分，主要有如下两类：

- **计算机网络系统的数据库化**，主要是用于存储数据，有各种类型的数据库应用程序。

    - 常见的结构化数据库SQL数据库有有多种，比如开源的免费的My Circle。  

- **分析计算用的数据库化**，主要是通过建立数据库，用于统计分析软件的计算。

    - 我们这里所学的就是这一类数据库化。

我们主要学习常用的运用于计算机**单机**统计计算与分析用的数据库化。

大数据的数据库化有不一样的特点和需求。

---

## 数据的数据库化示例


SPSS是社会科学统计计算运用比较多的一个大型统计计算软件

SPSS数据库的数据视图：

- 每一行代表样本，
- 每一列代表变量
- 中间单元格表示数据取值


SPSS数据库的变量视图

- 每一行代表一个变量
- 每一列表示变量的性质和特征


---

## 调查数据的数据库化（主要步骤）

问卷调查的数据，在完成了问卷的审核、归档、清理以后，在用于分析软件的分析之前，就需要把它转化为数据表示的数据库。通常有三个步骤：

- 第一步，**编码**。

    - 在清理工作中，这项工作应该已经完成了，不过在数据入库之前还需要审核。

- 第二步，**数据录入与转化**。

    - 如果是纸版问卷调查，这个时候就需要录入数据。建议采用专门的**录入软件**进行录入，尽量避免录入中出现的差错，进而降低调查误差。
    - 如果是计算机辅助调查，这个时候就需要转化数据。无论是内容转化还是格式转化，也建议尽量采用可靠的工具，避免出现差错。  

- 第三步，对录入完成和转化完成的数据，做基本的**检验和清理**。

    - 最容易出现的差错就是错行、错列造成数据的混乱。  


---

## 调查数据的数据库化（编码）

**编码**：就是把调查问卷的每一道访题用符号或者数字组合代码换，包括对每一道访题的选项或应答赋值。  

- 每一道访题的编码就是数据库表中的变量。 

- 应答赋值就是数据库表中的**变量值**，这个只有各种属性，就是数据库表变量视图中的各种标签，又称为**变量标签**。

我们来看例子，这是Self PS中的一道访题，  

> 【问题】1.5，请问您希望孩子念书，最高念到哪一个程度？（共７个选项）。 

> 【选项】A.小学；B.初中；C.高中；D.专科、职高、技校、大专；E.大学本科;F本科以上;G.不必念书

对这套**访题**我们可以这样编码，访题可以编为B15。（为什么这么编?）  
对选项的编码，就可以选项的编号。

---

## 调查数据的数据库化（编码）

问卷调查数据的编码，一般有三种方法：

- 第一：**原始编码**，就是直接运用问卷的编码。

    - 通常这种方法仅仅用在访题数量极少，应答非常简单的情况下。

- 第二：**先编码**，在调查开始之前，编码工作就已经做好了。

    - 通常这种方法会用在基本上都是封闭访题的情况下。  

- 第三，**后编码**，就是在问卷调查完成以后再做编码。

    - 只要是有开放访题，一般都会采用这种编码方式。  

无论是采用哪种编码方法，最后都有一项相同的工作，就是编制**编码部**。 

**编码部**相当于问卷数据的一个**索引**，把变量、变量值，变量标签关联起来，类似于一本问卷数据字典。  

---

## 调查数据的数据库化（录入）

.pull-left[

- 对于简单的问卷调查，可以运用常用的办公软件或统计分析工具来做录入，
  
    - MS Office Excel
    - Mac Numbers 
    - SPSS
    - Stata、statistica、R…  

]

.pull-right[

- 对于相对庞大复杂的问卷调查，需要使用专门的数据录入软件。

    - 商业收费的SPSS [Data Entry模块](http://www.spss.com.hk/software/data-collection/data-entry/)
    - 免费的[EpiData](https://www.epidata.dk/cn/index.htm)

]

专用录入软件的能提高录入效率，并减少录入误差：

- 可把纸版问卷计算机界面化，把纸版问卷完整呈现在计算机屏幕上。
- 可通过对跳转、阈值、变量类型等的控制，尽量减少录入所带来的误差。
- **双录入策略**，是采用同样的工具，在完整地录完第一遍以后，由同一个录入员，或者换一个录入员采用相同的方法录第二遍。
- 在录入完成以后，还可以直接把录好的数据导出为数据库表文件。


---

## 调查数据的数据库化（检验和清洗）

针对的已经数据库化的数据，通常需要运用**统计分析方法**进行检验和清洗： 

- 第一，录入错误清理。可以把双录入的数据输出为一个清理数据库，核对录入中出现的冲突数据。  

- 第二，编码清理。对不在编码值范围的变量值进行清理。 

    - 假设性别属性值的编码原本只有0和1，如果在数据表中出现了其它值，那就一定是哪里有错误了，就需要清理并且改正错误。
    
- 第三，逻辑清理。主要是针对基本事实逻辑的清理。  

    - 比如样本为男性，在是否怀孕的访题下，变量值说明他有怀孕记录，这就是逻辑错误
    
---

## 调查数据的数据库化（检验和清洗）

数据库检验和清洗还需要注意如下问题：


- **离群值**：偏离了日常理解的范围，但实际上可能是有效值的一部分。

    - 男性怀孕令人奇怪，女性怀孕就没有什么让人奇怪的了，对不对？
    - 女性16岁-49岁之间怀孕都是正常的。如果数据显示有一位七十岁的老奶奶怀孕了，  有没有可能呢？


- **极大值**和**极小值**， 都是需要再次确认的变量值。


- **无应答**的处理，通过分析已经应答的数值，确定对无应答的处理方式，比如差值。

- 变量的**再编码**，在数据的清理中也可以产生**衍生变量**。
    - 比如受教育程度或者年龄的重新分组
    - 比如依据受教育程度和收入来建构社会经济地位
    

---

## 调查数据的数据库化（清单）

正常的完成了数据库化的问卷数据，至少应该包括以下的文件：  

1. **调查问卷**（已经有了）

2. 调查问卷的**数据库编码手册**（已经有了）

3. **两个数据库**，一个是完成问卷的数据库，一个是未完成问卷的数据库。  

4. **样本数据库**，通常抽样完成以后，一定有一个数据库。这个数据库包括了用于抽样的变量、抽样单位、分层变量、权重变量等，这些应该是分析研究之前已经有的数据。  

5. **抽样报告**、**实施报告**，这两份报告用于判断数据质量，制订分析策略。  

6. 完成的、未完成问卷数量的**统计表**。通常用表格方式展示出来。 

7. **数据清理报告**，对变量的可分析性要进行说明。 


---

## 访谈调查数据的数据库化（主要步骤）

```{r, eval = FALSE}
database2 <- read_table("data-raw/qiu-database.txt", col_names =F,
           locale = locale(encoding = stringi::stri_enc_get())) %>%
  as_tibble()  %>%
  mutate(X2 =str_extract_all(X1,"(?<=text\":\")(.*)(?=\")"))

database2 %>% extract2("X2") %>% str_c(collapse = "")
```


对**访谈调查**的数据，在完成了访谈笔记的整理、格式化、归档、清理之后，在用于分析之前也需要把相关的信息录到数据库中。虽然不一定可以像问卷调查数据那样完全的数据库化，至少**访谈记录**与**整理信息**应该数据库化。

- 第一步，编码。
    
    - 记录信息的编码（重点工作）
    - 记录内容的编码（如果要进行**文本分析**，则需要此步骤）

- 第二步，录入。

    - 录入访谈记录信息，便于检索，也便于查找。
    - 如果要做内容分析，访谈内容就需要全部地录入。

- 第三步，清理。一般需要逐行核查。
    - 除了**记录信息**数据以外，**内容数据**是没有办法采用统计分析方法的进行核查


---

## 访谈调查数据的数据库化（编码）

访谈数据的编码有两类：

- **访谈记录信息**的编码。基本变量有记录编号、访谈时间、地点、人物、主题、位置图。如果有日志信息，也需要把日志信息加入其中。

- **访谈记录**的编码。如果希望编码的程度可以直接应用到**内容分析软件**的分析，那么就需要学习专门的课程，不同的分析软件对编码的要求是不一样的。


---

## 访谈调查数据的数据库化（录入）

.pull-left[

访谈数据的**录入工具**：

- 要是涉及到数字数据的，就可以使用Excel、SPSS、Stata、Statistica、r等等

- 对文本数据，就可以使用Word，当然也可以使用Numbers和Pages。

- 对访谈内容，还可以采用**内容分析软件**，比如Nvivo、Aquad、ATLAS.ti和Qualrus。

]

.pull-right[

访谈数据录入的**几个要点**：

- 录入策略问题。对于访谈记录信息的录入，尽量采用标准化的格式，目的是便于交换、便于交流。

- 文本格式问题。一般可以先转录为纯文本格式，注意纯文本格式有一个编码问题，最好采用通用的编码，比如Unicode。

]

---

## 访谈调查数据的数据库化（清单）

访谈数据的数据库化产出也有一份清单，至少要有以下的**数据文件**：


1. 调查提纲或者访谈提纲，或者访谈设计。

2. 访谈记录的整理、清理的数据库

3. 访谈内容的数据库

4. 访谈记录的数字化，也就是数字化的过程及报告

5. 最后还有清理报告


---

## 观察数据的数据库化（主要步骤）

**观察数据**怎么数据库化呢？主要也是三个步骤：

- 第一步，编码。

    - 观察调查数据的编码与其他编码不一样的地方在于观察记录信息比访谈记录信息要丰富得多。当然对观察记录的内容，如果希望用作分析素材，也需要编码。

- 第二步，录入。

  - 在大多数情况下，主要录入观察记录信息，同样，如果要把观察记录的内容作为统计分析的素材，那么也需要把它录到数据库中。

- 第三步，清理。

  - 同样在录入完成之后，要对已经录入的数据进行核查，如果有观察记录的内容，就需要对已经数据库化的内容做仔细的核查，确保内容准确。


---

## 观察数据的数据库化（编码）

观察数据的编码主要包括两个方面：

- 观察记录信息的编码。基本变量包括记录编号、观察的时间、地点、事件、主题，还有观察媒体（望远镜/摄像机/眼睛）。如果有**日志信息**，也可以把日志信息列入其中。

- 观察记录内容的编码。即使观察记录的内容不会作为统计分析的素材，最好还是录入为数据化的文本文件，便于交流。


---

## 观察数据的数据库化（录入）

观察记录的录入

- 文本数据、数字数据的录入。采用word或pages录入。

- 图片数据的录入。可以采用类似于Adobe的Lightroom之类的数据库。可以先扫描，再录入记录信息。

- 视频数据的录入，则可以运用类似于Adobe Premier之类的编辑库。

- 音频数据的录入，也可以寻找适用的音频数据库。

---

## 观察数据的数据库化（清单）

一份完整的数据库化的**观察数据**的数据库， 至少要提供以下的数据文件：

1. 观察提纲或者观察设计；

2. 观察记录的整理、清理数据库；

3. 观察内容数据库； 

4. 观察记录数据数字化、数据库化过程的数据；

5. 清理报告。

---

## 文献数据的数据库化

**文献数据**一般情况下原本就来源于数据库。因此，运用原来数据库的数据，是文献数据库的特点。文献数据的数据库化包括三个步骤：

1. **编码**。指的是**文献信息**的编码，而不是**文献内容**的编码，文献信息就是**编目信息**，文献内容就是文献记载的内容。

2. **录入**。就是把原来数据库的文献编目信息和文献内容抄录到研究用的文献数据库中去。

3. **清理**。就是在数据录入完成以后，对录入的数据进行核查、清理，包括完整性检查。

---


为了确保同学们已经掌握了文献编目信息，我重复一遍文献的编码。

- **文献记录信息**的录入和管理。

    - 基本变量主要有作者、篇名、时间、载体、存放、DOI，或者ISBO，或者ISNN等。
    - 文献记录的编码可以直接运用文献记录的原始编码，一些数据库化的数据，比如jasdo，还支持编码的数据直接导出。
    - 专门的信息录入和文献管理软件：Endnote和papers。

- **文献内容信息**的录入和管理。
    - 主要管理的是文献内容、阅读笔记、思路图谱、总结要点等
    - 专门的内容录入和关系管理软件：onenote、Mindmanager、印象笔记等。


---

## 痕迹数据的数据库化（简要）

**痕迹数据**的数据库化，无论是Map-Reduce的产出，还是网页爬取的数据的整理、清理时的产出，都是**基于变量**的数据，还没有把变量数据串起来，变成**基于样本**的数据。

样本在变量上的变异是分析工作的基础，数据库化需要做的工作就是把变量数据串起来，变成类似于样本数据的数据。串起来的方法很多，技术性也很强，基本上依靠**脚本**来完成。

如果从大数据中抽取数据，由于无需数据录入，故数据库化只有两个步骤可做：

1. **编码**。通常原有的数据就已经有编码了，这个手续要做的就是要么确认使用原来的编码，要么呢，因为特殊的原因，需要重新编码，何去何从，完全取决于计算的需要。

2. **清理**。与其他调查数据的清理不同，这里主要是在确认编码以后，确认数据的可计算性，也就是格式化、结构化在转化中没有发生问题，以及是否可以直接运用于分布式并行计算或者单机计算。



---
layout: false
class: inverse, center, middle, duke-softblue

# 2.6 数据质量

---
layout: true
  
<div class="my-header"></div>

<div class="my-footer"><span>huhuaping@   第02章 数据收集、整理和清洗   
&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;
&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;
2.6 数据质量</span></div> 

---

## 数据质量（评判原则）

> 没有质量的数据，就是垃圾。“垃圾进，垃圾出”。

> 数据的质量会受哪些因素的影响？如何评估数据质量？


数据质量评估是一项专门的技术，对不同来源的数据，有不同的评估方法。判断数据质量的基本原则有三项：

1. **真实性**。真实性指的就是数据确实来源于调查，与数据产生有关的过程真实存在，调查对象真实存在；访问、观察真实存在；应答、场景、文献真实存在。

2. **准确性**。数据的调查人员准确按照研究设计在执行，准确地处理了调查对象和调查对象的反馈，或者是，准确地转录了原始数据。

3. **时效性**。 对于有时效要求的数据，还要考虑调查的 实施过程是不是符合规定的时间要求。 如果上述三项原则都能得到满足， 就可以进一步考察数据的基本质量，那就是符合性。 

---

## 数据质量（评判维度）

对于数据质量的评估，总体上有两个维度： 

1. 正向评估，就是与标准要求的距离到底有多远，也就是符合性问题。

2. 反向评估，就是误差的大小。


---

## 数据质量（误差分类1）

事实上，数据收集、整理、清理的每一个环节都有可能产生误差。 

1. 覆盖性误差。就是涉及到调查对象的备选机会而可能产生的误差。抽样问卷调查、访谈调查、观察调查、文献调查都有可能产生覆盖性的问题。 

2. 测量性误差。就是调查数据中可能产生的误差。调查大都涉及到测量的信度和效度。只要信效度有问题，那么测量性误差就可能存在。 

3. 应答性误差。 观察调查、文献调查看起来没有应答类型的问题，实际上不是。只要是访问员提出的要求都存在应答类型的问题。 只是不同类型的调查，应答性误差的表现形式、计算方法不同。因此，应答性误差也是调查数据中可能存在的误差。 

4. 抽样性误差，仅出现在抽样问卷调查中的一类误差。


---

## 数据质量（误差分类2）

以上误差，如果依据在调查活动中的**可改进性**来看，又可以被归纳为两类误差：

1. 随机误差，就是在调查活动中随机产生的误差.

    - 比如访问员的不规范行为产生的误差。通过规范访问员行为就可以减少这一类型的误差。在表现形式上，这类误差会增大变量测量的方差。 

2. 系统误差，是由设计因素影响所产生的误差。

    - 比如测量工具带来的误差，由于测量工具有问题，导致凡是采用这个测量工具的调查都会产生同一类、甚至同样程度的误差。 在表现形式上，这类误差会增大测量的偏移量，就是bias。


**调查总误差**：所有这些由数据收集、整理、清洗活动产生的误差的综合，被称之为**调查总误差**。通常用**均方误（MSE）**来表示。

均方误是系统误差和随机误差两者合起来在误差上的反映。在统计上，就等于偏差的平方加上方差。 

---

## 覆盖性误差（概念）

 
**覆盖性误差**，又称为**抽样框误差**，指的就是**目标总体**与**抽样框总体**不一致所导致的调查对象错位所产生的误差。 

覆盖性误差存在于所有通过调查方法获取数据的研究活动中。

- **目标总体**就是调查对象总体，有明确的调查对象所指。 

- **抽样框总体**，简称框总体，是用于抽样的所有调查对象的集合。 

- **样本总体**，是被抽中的，且被作为调查对象的集合。 

>文献调查中， 已知需要查阅的涉及某件事的所有文献，在查阅之前，却打算把查阅文献的范围扩大或者缩小，这就产生了覆盖性误差。 

???

对调查数据的各种误差， 建议大家参阅Rober Groves等人编写的《Survey Methodology》《调查方法》，这是一本研究生的教材，第二版的中文译本2015年上半年由重庆大学出版社出版。 这本教材把涉及到调查活动的主要误差类型以及计算方法讨论地非常透彻。

---

## 覆盖性误差（来源）


1. 丢失或者重叠目标总体要素。
    - 框总体小于或者看起来大于目标总体，进而让部分要素失去或者获得了多次被抽中的机会，这里既有覆盖过度的现象，也有覆盖不足的现象。
    - 比如在“北京大学本科生入学机会地区不平等”的调查中，如果以已经入学的学生为总体，丢掉了某个院系， 或者既用院系、又用地区做抽样框， 就会产生丢失，或者重叠问题。 

2. 在抽样框总体中，包含着非目标总体要素。
    - 这会使得况总体看起来会大于目标总体，进而让目标总体的备选概率小于理论概率
    - 比如“北京大学本科生入学机会的地区不平等”研究，把北京大学的保安纳入到了抽样框，就会让目标总体学生的备选概率降低。

3. 不正确的辅助信息。
    - 在分层抽样中，如果使用了不正确的辅助信息，就有可能让层要素的备选概率大于或者小于理论概率。 

---

## 覆盖性误差（影响）

那么覆盖性误差对调查误差到底会有怎样的影响呢？ 

- 如果是**抽样问卷调查**，那么就会通过影响等概率，进而影响到代表性，影响了代表性，就影响到数据质量。 

- 在**非抽样问卷调查**中，虽然不存在影响等概率的问题，但覆盖性问题依然存在，只是表现形式不同而已。 如果覆盖过度，虽然不会对调查数据质量造成可计算的影响，却可能会干扰研究判断，比如冲淡了真正对象的变异性或者影响。如果覆盖不足呢，则有可能对研究判断造成致命的影响。
    - 在文献调查中，缺失了最关键的文献就有可能会认为没有这类文献，进而出现错误判断。
    
    - 在访谈调查中，如果没有访问到事件的当事人，就有可能出现关键信息不全甚至缺失，进而也导致错误的判断。 
    
    - 在观察调查中，漏掉了关键的场景，比如研究庙会的，却没有去观察某个庙会，就无法对场景的现象做正确的判断。 


---

## 测量性误差

**测量性误差**，指来源于测量工具的误差，和运用测量工具的误差。

> 在测量长度的时候你拿着尺子来量，尺子很准，很可靠，不过呢你的眼神不好，测量过程就有可能带来误差。

> 如果工具不好，即使你非常认真，也会产生误差。如果工具很好，没有用好，也不行，也会产生误差。


两个来源的误差都会反映在测量的质量参数上来，这就是**信度**和**效度**。

- **信度测量**：前后测信度、折半信度、复本信度、一致性信度。 


- **效度测量**：表面效度、准则效度（校标效度）、建构效度、内在效度。

信度和效度的测量是针对**结构式测量**的。事实上**无结构式调查**中也同样存在信度和效度问题。 只是因为没有结构，对信度和效度的测量比较困难而已。

---

## 测量质量的检验1（信度）

假设我们从概念的变量化开始，到选择测量策略、策略工具，甚至已经完成了测量。
我们怎么就能够对社会、对同仁说：”诶，我的测量不错，是值得信赖的。“ 如何评价测量的质量呢？这就是这一节我们要讲的内容。
我们先举一个例子，大家生活中的例子，称体重，是测量对吧？我们就以称体重
为例，你去体检，称体重，如果称的体重超出了自己的预期，尤其是女生
会有什么样的反应？就会宣称：”诶，这个称有问题。“是不是？
如果张三说不准，李四说不准，王五也说不准，大家众口一词，说：“别上那去称啦，那个称- 根本就不准。”
这时候，我们就会怀疑测量工具有问题。
在社会调查与研究中，测量的质量非常重要，甚至可以说测量质量
就是测量的生命线，就是数据的生命线。
大家应该还有一个体验，尤其是男生，在窗口打菜
买饭，哪个窗口卖的比较公平，哪个窗口给的比较少，这也是对测量的评价。
你们现在生活的时机很好，不缺吃，不缺穿，我们读书的那个年代，谁要是给的少，那可糟糕啦
他会遭到很多的攻击的，我们那个时代是短缺的年代。
遗憾的是到目前为止，对社会调查与研究的测量质量 既没有国家标准
也没有国际标准，有的是一个事实标准，就是一个 工具如果不断的有人宣称质量不错，并且通过相关的检验，的确不错
那么就是不错。在美国针对调查，美国的舆论调查协会有一整套针对调查的标准。
这个呢，大家可以在网上查到。AAPOR的标准 和学术界的事实标准，主要还是专家的标准。
针对社会调查与研究的测量，大家用的也是专家标准。
而专家参照的呢，主要是看现象与测量工具、测量结果
之间的吻合程度。如何检验吻合程度？在学识界形成了共识是
使用效果和信度进行检验。从第一周的课程开始我们就不断隐约地在提信度
比如，不断地讲规律的稳定性、测量的稳定性等等。
信度是什么呢？很简单，就是指 使用同一个测量工具、重复测量同一个对象，得到相同结果的概率。
得到相同结果的概率越高，测量工具的信度也就越高。
信度对测量而言，就是测量工具的稳定性。
如何检验测量工具的信度呢?
假设我们在做调查，用问卷在做调查，用访题在做测量
如何测量访题的信度。我们有多种测量方法，比如说，采用前-后测，大家还记得前-后测吧
这里就用上了。前-后测，在检验测量信度时，有一个特殊的概念，叫
“重测信度”，看前后之间有没有差异 前后之间的差异越小，信度就越高。
由于前-后测在实践上一前一后，所以呢，又叫垂直重复信度。
不过需要特别提醒的是采用前-后测检验信度时，时间不能是影响变量的因素
变量不能随时间的变化而变化，如果随时间的变化而变化，那就麻烦了
你怎么测都测不准。采用重测办法来检验质量，越测越糟糕。
如果变量随时间的变化而变化，那么，对测量工具的检验就不能采用
前-后测的方法，而可以采用复本信度的方法，又叫：“等值信度”，也是
水平的重复测量，同时测。当然采用复本信度的方法也有条件，那就是 测量对象具有等价性。
只有对象具有等价性，才能评价测量工具的稳定性。前后测
平行测，在实验设计中已经有充分的讨论
这里就不重复了。这一些都是单个访题的信度检验
但如果是质量和量表又怎么办呢？尤其是针对主观变量又如何检验
测量的信度呢？我们知道指标和量表的特殊性是一组访题。
一组访题之间在测量上的一致性会直接影响到指标和量表的稳定性
为此有两种方法来测量一组访题在测量上的一致性。第一种方法叫对分法
又叫折半信度，方法是假设我们有一组访题，无论是指标还是量表，尤其是指标
至少有两道以上的访题，一般是5-6道，或者6-7道 就业满意度就有19道访题。第一，把访题编号，编成奇偶数。
第二，对同一组对象，用奇数题和偶数题
分别进行一次测量，计算奇数题偶数题得分的相关系数即折半信度。
第四，再用Spearman Brown公式计算信度。
理论上，如果访题的一致性很好，奇数题得分与偶数题得分之间的相关系数
也应该很高，如果访题之间的一致性有问题，相关系数也不会高
就说明访题的稳定性不高，面对这种情形，就需要修改测量工具了。
第二种检验内部一致性的方法就是运用 克隆巴赫系数，又称之为“Cronbach α”。
克隆巴赫系数运用了内部方差原理，也就是如果访题的内部方差越大
则测量的一致性也就越差，具体计算方法随后我们会讲。
测量中除了测量工具，还有测量者，测量的人，也是影响 工具稳定性的重要因素。还是以称体重为例
如果观察体重计的人不好好工作，读出来的读数就会有很大的差异。
如此我们知道，对测量工具稳定性的检验包括两方面的内容
一是对工具稳定性的检验，第二是对工具使用者稳定性的检验。
现在我们要简要讨论一下克隆巴赫 alpha系数的计算，内部一致性计算的一种，Cronbach's alpha。
很简单，我们可以看一下alpha的计算方法，上面是n,下面是n-1 n代表访题的总数，这个组数主要是
用于避免小样本条件下因访题数量变化所带来的误差。
再看括弧里面，有人可能一看见统计公式，脑子就会蒙，其实把含义搞清楚了就非常简单。
Si的平方表示用第i道访题测量了很多次
访题得分的方差，又称之为内部方差，比如说某个访题测量了50次，50次
就有一个平均值，再用每一次测得的值减去平均值的平方，是不是就得到了方差
也就是这一道题的内部方差 把每一道题的内部方差合起来再除以所有题的总方差
就是一组访题的差异性，用1减掉差异性是不是就是一致性。
再考虑小样本统计的特征，就得到了 克隆巴赫系数a，a系数越高
表示内部一致性越高，指标和量表的可靠性 也越高，a大于等于0.9属于极好的测量
a大于等于0.8，小于0.9，就已经很好了，一般而言呢 大于等于0.7就可以接受了。
如果是初次制作指标，多测几次，多改几次就会越来越熟悉，试试看
这是最通用的也是最常用的，尤其是在公共卫生的调查与研究中
指标和量表的内部一致性检验常用的检验方法
非常重要。公共卫生大多数针对的是健康状态、健康观念，,就会用到指标和量表。
我们回顾一下对信度的检验，如果是单一访题，就采用重复测量方法
要么前后测，要么平行测，看多次测量之间的相关性
相关性越高，表示工具的稳定性越好，针对指标和量表，对访题的检验至少有两种方法。
一种是折半信度，直接看内部一致性；一种是 克隆巴赫系数，通过考察内部的差异性来检验一致性。
无论是针对单个访题还是一组访题 访问者也是影响测量信度的重要因素。
这是最最基本的测量工具的检验方法，更加复杂的就不在这里讨论了。
对测量工具而言，不仅要工具可靠，还要工具正确，称体重就不能用米尺 如果用错了工具，再稳定地测量也无益。
这就是效度。效度指的就是 对的测量工具，问题是我怎么知道工具对还是不对呢
效度的检验就是为了回答这个问题，效度指的就是测量工具在多大程度上
真实地反映了要测的属性，对效度的检验就是对测量工具有效性的检验。
我们知道，对是否是研究者希望测量内容的判断
更多的属于主观判断，因此对效度的第一个判断，就是看起来是不是 要测量的内容
表面效度，就是测量获得的结果与人们的共识的一致性。到底谁来确定测量的效度呢？
其实取决于在同行中能获得 多大的共识，专家在其中扮演着重要的角色。
这一节的内容还没有结束，先休息一会。

---

## 测量质量的检验2（效度）

现在，我们接着前面的内容，讨论效度检验的其他方法。
除了表面上看起来有效，还有一些其他的检验效度的方法，比如
标准关联效度，又称之为效标效度，准则 效度，含义是一样的。只有一个标准站，比如说温度
不管采用摄氏测量，还是采用华氏测量，有绝对温度作为标准 就可以检验两个工具的测量有效性。
与标准相比，看关联性有多高，就
表示效度有多高。如果比较的标准与测量结果之间会受时间的影响
则还有预测效度、同时效度。预测效度，一个始点的测量
结果与另一个始点测量结果之间的相关程度，相关程度越高 预测效度也就越高。同时效度，指的是测量结果与
既有的有效测量之间的相关程度，相关程度越高 同时效度也就越高，比如，笔试与实际能力之间的关系
既涉及到预测效度，也涉及到同时效度；还有，一模、二模的成绩能在多大程度上预测高考成绩
就是模考的预测效度。如果不是一道题，而是一组题，就会涉及到结构效度。
结构效度，指一组题在多大程度上可以测量到理论上 期望的特征，比如说，在多大程度上能测量到
事物之间的关系模式 比如，一组题，能在多大程度上发现婚姻满意度与夫妻之间相互忠诚之间的关系模式。
如果是直接测量变量的属性 就涉及到内容效度，测量在多大的意义上包含了概念的含义。
我们用的最多的一个例子：身高和体重，用什么测？
效度的检验不像信度的检验，总是需要用到统计检验，大多数的情况下都是主观判断
也有复杂的效度测量，难度超出了课程的要求 大家知道这些就够了。任何做测量的人
都希望测量工具的信度好，效度也好，只是在实践中
信、效度之间常常需要大家取舍，这是因为信、效度之间始终有着内部张力。
还是用例子来说明吧，比如说操作化，当我们有一个概念，把它操作为可测量的变量时
可能损失概念的内涵，造成效度上的难题。还记得北京大学本科生入学机会
地区不平等的研究？比如说，我们把地区之间的差距操作化为 地区之间的人均GDP，虽然测量起来比较容易
可是测量的并不是每个地区人们可以用于教育的资源。
测量人均GDP倒是很稳定，信度很好，却没有很准确地测量到 我们希望测量的、可以用于教育的资源。
同样，我们追求效度，测量每一个毕业生家庭可以用于教育 的资源，虽然测量到了要测量的内容，可是测量起来却很困难。
同一个家庭，每次的回答都不一样，工具极不稳定。
这就是信度与效度之间的张力，如果希望测到变量的准确属性
就会面临到重复测量的稳定性问题。如果希望重复测量稳定
就会面临不能准确地测量到变量属性的问题。
在测量的质量检验中还有一个问题是需要注意的
这就是对测量精度的选择。不管是哪一类变量的测量，都有精度选择问题。
还是我们自己的课题，比如说地区的分类，分几类合适呢？
理论上，分类越细致，越便于观察差异，实际上由细致分类带来的差异可能也很大
再比如家庭收入，到底是计算到元，还是计算到千元？
GDP，计算到元，如果你这么做了，同行就一定会骂我，说我没有把你们教好。
某个烟摊某天的零售额计算到千元，保准你不知道测到了什么。
从这些例子我们知道，在测量和测量检验中，测量的精度选择
也是需要注意的问题，怎么选呢？还是要依据测量变量的情境 比如，用于测量入学机会地区不平等的地区
就不宜划分过细，也许三类足矣。
北京大学学生的年度收入与支出精确到元，甚至精确到十元、百元也就足矣。
非常非常重要的是，测量，在调查与研究中，是一个妥协和取舍的过程。
在满足对误差要求的前提下，尽可能地节省资源 尽可能地让信度和效度之间平衡，是最重要的。
不管是什么精度，测量还是要有信度和效度，既要求有一定的可靠性
也要求有一定的准确性。精确
显然不等于准确，不精确的测量可能会非常的准确，比如说，具有学士学位
比受教育17年哪个更加准确？很显然，对学历测量而言
前者不精确，却很准确。下边我们把这一节的内容做一个小结。
到目前为止，在学识界，对测量的质量 没有明确的标准，有的是学识界认同的一些标准，共识的标准。
其中两个重要的参数，就是信度和效度。
信度，是用来检验测量可靠程度的
效度呢，则是用来检验测量有效程度的。在同一个测量中，在信度和效度之间
我们常常需要做取舍，做权衡。除了信度、效度以外 测量精度是初学者常常忽略的一个问题
对精度的取舍，取决于研究变量对误差的要求。
这一节的内容就到这里。
下边，我们对这一周的内容做一个小结。
这一周的内容跨度比较大，从概念就跳到了测量了。
通过上一周的选题，数据来源的选择，就进入到了
调查与研究工作的全局性操作阶段了，包括概念化、操作化、测量工具和
测量的质量检验。概念的变量化有两个阶段，第一个阶段是概念化
对概念指称的事物归纳，形成概念
再把概念的关键属性抽提出来，转化为可测量的变量，这项工作
是调查与研究操作化的基础，通过变量化，研究问题也就转化成了
变量之间的关系模式，或者一组变量之间的关系模式。
在这个过程中，概念内涵的确认与维度的选择 是概念化和操作化的基本技能，需要真正的创造性。
为了便于测量，在学识界，人们建立了共识，根据 变量属性值的特征，把变量分为4种类型
定类、定序、定距和定比，每一类变量都有不同的数学特征，不仅如此
在关系模式的检验中，还记得我们在上一周讨论中说过的 每一类不同的关系还有不同的检验方法。
有了变量关系模式，接下来就是对变量进行测量 通过测量获得数据，来检验变量之间的关系模式。
变量测量的基本工具是访题，针对不同类型的变量
访题的运用也有不同的特征，对某些定序变量的测量 则需要采用一组访题的指标法或者量表法。
对指标和量表的有效性，需要通过内部一致性的检验。
制作指标和量表是一门专门的技术，有兴趣的同学
可以查找相关的参考文献进行阅读。测量的质量检验是测量的重要一环
信度和效度，是基本的参数，不过对一项具体的测量而言
调查和研究者还需要进行取舍，因为两者之间始终存在着内部张力。
同学们，上一周就选好了题，选好了数据的来源，现在就要进一步地把它变量化了
并要选择好自己的测量工具了，有的同学说：”老师，我准备用已有的数据。“
我的建议是：你就假设没有现成的数据，你准备自己搜集数据。
这样我们的研究实践就比按部就班地进行下去 让大家在社会调查与研究的每一个环节都得到练习的机会。
这一周的研究实践完成以后 同学们已经选好的题目就变成了概念、变量、变量之间的关系模式、测量策略
测量操作策略、技术路线、技术难点、难点与创新、测量的检验策略等等
这就是，由一个题目引出的故事。这一周的课程内容到这里就结束了，谢谢大家。

---

## 应答性误差（概念）

**应答性误差**，是指访员发出了调查请求，调查对象却没有做出回应或者做出应答，由此带来的直接后果就是调查数据的缺失，从而引起数据误差。


在不同的调查中，应答性误差的表现形式并不一样， 

数据缺失如果是样本层面的、对象群体层面的、场景层面的、文献类别层面的，那么应答性误差就可以被理解为**广义覆盖性误差**中的一种。 

即使我们获得了等概率样本，或者必须调查的对象列表，在调查中，调查对象拒访、场景不可及、文献不可及等等情况总是会有的。

即使接受了访问，场景也可及，文献也找到了，可是某几道访题受访者不作答，或者不知道如何作答；或者没有遇到具体的场景。

> 希望看婚庆，但没有遇到有人结婚；或者文献中的某几页缺失了。

如此，就相当于覆盖不足，或者数据缺失。 

---

## 应答性误差（概念）

无应答从类型上看主要有两种。

1. **对象无应答**：

    - 在抽样问卷调查中，常常被称之为**样本无应答**，或者**单元无应答**，英文是**unit nonresponse**；
    - 在非抽样问卷调查中，对象无应答被称之为**“失访”**，就是没有接触到、观察到或者访问到设计中需要调查的对象、文献、痕迹。

2. **某些议题没有得到应答**：
    
    - 在抽样问卷调查中，如果部分访题没有得到应答， 就会被称之为**选项无应答**，又被称之为 项目无应答，英文叫**item nonresponse**。
    - 在非抽样问卷调查中，指一个或者具体几个议题，没有“访到”，自己忘记了、遗漏了，或者缺失了。 

---

## 应答性误差（应答率）

在抽样问卷调查中，**应答率**是评估数据质量的基本参数之一。应答率等于**应答样本数**除上**样本总数**，再乘上百分之一百。

.pull-left[

从**分子**角度来看：

- 一种情形是完全应答， 完成了所有应回答的访题。

- 另一种情形是如果只是部分地应答了，没有完成所有应该回答的访题呢，那么到底完成了多少算是应答了呢？通常会根据访题的数量算出一个百分数，也就是完成了百分之多少访题的应答率是多少。 

]

.pull-right[
   
从**分母**角度来看：

- 无效的样本， 比如不符合样本约束条件的对象； 

- 未接触到的样本，也不知道是不是符合样本的约束条件； 

- 接触到了，却完全无应答的样本； 

- 即使没有接触到，却被认为是有效的样本； 


]

???

不同的分子和分母组合算出来的应答率都不一样， 在说明应答率的时候，需要详细说明。

应答率有不同的计算方法，如果希望了解详细的计算方法，可以通过互联网查找美国舆论调查协会AAPOR所提供的计算方法。

---

## 应答性误差（影响）

应答率对数据质量有什么影响呢？ 

假设应答率为
$p$，无应答率其实就是
$1-p$， 由于无应答既可能是**随机现象**，也可能是**系统现象**。

- 随机现象，比如某个访题遗漏了，某个样本遗漏了；

- 系统现象，比如高收入的人群完全接触不到。

因此，无应答对样本估计值的影响主要来自于满足约束条件的样本的无应答，对代表性的影响。

- 高收入人群完全访问不到就会造成这一部分人群没有样本，进而影响到让样本满足等概率性。 



---

## 抽样性误差（内涵）

在抽样调查中，覆盖性误差、测量性误差、 应答性误差，三类误差都是可计算的。

抽样调查中抽样性误差的来源

- 主要来自于制作抽样框时候形成的误差，比如对样本的覆盖性。换句话说，在抽样调查中，覆盖性误差其实是抽样性误差的一部分。 

- 还有在抽样过程中形成的误差，比如分层、多阶段，尤其是在末端抽样中，采用的方法、抽样的人都有可能形成误差。

在文献调查中，因为使用二手文献、因为选择版本等所带来的误差；

在观察调查中，因为选择场景所带来的误差。 

在访谈调查中，因为访谈对象变动所带来的误差。

---

## 抽样性误差（计算）

抽样误差的计算也是针对具体变量的。 

>抽样的目的是为了获得有代表性的样本；获得有代表性的样本是为了用样本推论总体，误差尽可能的小；而推论是针对具体变量的推论；可是任何一项调查，误差总是要体现在这个变量上的，没有变量，哪来的误差呢？

1. **均值的变异系数**。等于样本均值除以标准误，也即 $\frac{\bar{X}}{\sigma}$。如果是比例值，则为
$\frac{p}{\sqrt{p(1-p)}}$。经验上，如果一项调查样本均值的变异系数小于50%，就认为质量是可以接受的。

2. **样本均值的相对方差**。等于样本方差除上均值的平方，也即
$\frac{\bar{X}}{\sigma^2}$。如果是比例值，则为
$\frac{p}{p(1-p)}$。


---
layout:false
background-image: url("pic/thank-you-gif-funny-little-yellow.gif")
class: inverse,center
# 本章结束
